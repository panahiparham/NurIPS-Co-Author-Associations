{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NurIPS Co-Author Associations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+fDa+0HPUBDfhhsogr/n1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panahiparham/NurIPS-Co-Author-Associations/blob/main/Project_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NurIPS Co-Author Associations\n",
        "\n",
        "## Abstract\n",
        "With the rapid advancement of science, the volume of published research papers is growing exponentially making the task of searching and finding relevant articles especially difficult for students and researchers. Another issue is the increased complexity in the relationships between papers, their references, and their authors. This study focuses on using the A-priori algorithm to find frequent co-authors of papers and then extract pair-wise association rules between them. These tasks are performed on the NurIPS papers database. \n",
        "\n",
        "## Purpose \n",
        "This project aims to find interesting relationships between Researchers publishing papers in the Neural Information Processing Systems Journal.In particular we are interested in three questions:\n",
        "  1. Who are the most published NIPS authors and their publications?\n",
        "  2. Which groups of researchers have published several papers together?\n",
        "  3. Which frequent authors, have always colaborated with a specific co-author?\n",
        "\n",
        "The purpose of this work is to better understand the research landscape of Deep Learning and ease the process of finding interesting researchers and papers.\n",
        "\n",
        "\n",
        "## Overview of Project\n",
        " * Extracting data\n",
        "  - Web scraping with beautifulSoup\n",
        "  - Hashing and storing paper and author names to disk\n",
        " * A-priori Algorithm for frequent pair mining\n",
        "  - Implementing 2 pass A-priori\n",
        "  - Implementing general multi-pass A-priori\n",
        " * Association Mining\n",
        "  - Generating association rules\n",
        "  - Gerfect implications\n",
        " * Discussion\n",
        "  - Confidence vs. Interestingness\n",
        "  - Future work\n",
        "  - Final note\n",
        "\n",
        "\n",
        " <em>\n",
        " </br>\n",
        "This work is designed as the final project for \"Algorithms for Datascience\" class offered at Shahid Beheshti University in Fall 2021.</br>\n",
        "<b>Instructor</b>: Dr. Ali Katanforoush</br>\n",
        "<b>Student</b>: Parham Mohammad Panahi (student id: 400422166)\n",
        " </em>"
      ],
      "metadata": {
        "id": "lfI_ZzCjCT4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting data\n",
        "\n",
        "## Web scraping with beautifulSoup\n",
        "NIPS posts lists of accepted papers on their website. In order to have access to papers and their authors we need to gather this data from NIPS website, [NeurIPS Proceedings](https://papers.nips.cc/).\n",
        "\n",
        "This page links to lists of papers for different years, we can scape these pages with [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/)."
      ],
      "metadata": {
        "id": "MkKFZIqrwRFW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXG9GVITtZbN"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations, product"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path to site\n",
        "root_path = 'https://papers.nips.cc/paper/'"
      ],
      "metadata": {
        "id": "1b0BzrTEt4ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract paper title, year of publishing, and author names for NIPS papers in a given year.\n",
        "def extract_paper_info(year = 2020):\n",
        "  r = requests.get(root_path + '/' + str(year))\n",
        "  soup = BeautifulSoup(r.text, 'html.parser')\n",
        "  papers_list = soup.find(class_='col').find_all('li')\n",
        "  return map(lambda x: {'title':x.a.text, 'authors':x.i.text.split(', '), 'year':year}, papers_list)"
      ],
      "metadata": {
        "id": "PswNqPODvAd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all paper data from 1998 to 2021\n",
        "counter = 0\n",
        "\n",
        "with open('nips_authors.csv', 'w') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=',')\n",
        "\n",
        "  for year in range(1998, 2022, 1):\n",
        "    # sleep the program between calls to server not to overload servers with requests\n",
        "    time.sleep(1)\n",
        "    for paper in extract_paper_info(year=year):  \n",
        "      title = paper['title']\n",
        "      year = paper['year']\n",
        "      authors = paper['authors']\n",
        "      row = [title] + [year] + authors\n",
        "\n",
        "      # write (title, year, author_1, author_2, ...) to disk\n",
        "      writer.writerow(row)\n",
        "      counter += 1\n",
        "\n",
        "print(f'found {counter} papers!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjbOcuql1MAf",
        "outputId": "1ddb8d19-0e4c-45d0-c931-06eea2f7180d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found 12461 papers!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hashing and storing paper and author names to disk\n",
        "\n",
        "We found over 10 thousand papers! To easily store and work with our data, we can hash each paper title and author names to a 32 bit integer and store these hash values to a csv of the form\n",
        "\n",
        "```\n",
        "paper_id, author_id, author_id, ...\n",
        "paper_id, author_id, author_id, ...\n",
        "paper_id, author_id, author_id, ...\n",
        "...\n",
        "```\n",
        " \n",
        " We also save a key value pair of id_2_author and id_2_paper to be able to easily convert hash values back to string representation later on."
      ],
      "metadata": {
        "id": "XrVpIeq2BPCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# two dictionaries to perform inverse hashing on ids\n",
        "id_2_paper = {}\n",
        "id_2_author = {}\n",
        "\n",
        "with open('nips_authors_id.csv', 'w') as writing_to:\n",
        "  writer = csv.writer(writing_to, delimiter=',')\n",
        "  with open('nips_authors.csv', 'r') as reading_from:\n",
        "    reader = csv.reader(reading_from, delimiter=',')\n",
        "    for row in reader:\n",
        "      title = row[0]\n",
        "      year = row[1]\n",
        "      authors = row[2:]\n",
        "      row = []\n",
        "\n",
        "      # keeping only the first 32 bits of the hash value\n",
        "      paper_id = hash(title) & ((1<<32)-1)\n",
        "      id_2_paper[paper_id] = (title, year)\n",
        "      row.append(paper_id)\n",
        "\n",
        "      for author in authors:\n",
        "        author_id = hash(author) & ((1<<32)-1)\n",
        "        id_2_author[author_id] = author\n",
        "        row.append(author_id)\n",
        "\n",
        "      # write (paper_id, author_id, author_id, ...) to disk\n",
        "      writer.writerow(row)"
      ],
      "metadata": {
        "id": "FhyiHnZh2zbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Found {len(id_2_paper)} papers in total!')\n",
        "print(f'Written by {len(id_2_author)} distinct authors')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwPIhQCx8D1Y",
        "outputId": "fcdd5f69-836a-414b-806c-7ac5b09a4667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12461 papers in total!\n",
            "Written by 20263 distinct authors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like there are over $12000$ papers published in NIPS since its inception, with over $20000$ distinct researchers contributing to this figure.\n",
        "\n",
        "In order to count the number of papers on which any two authors worked together, we need $ 20263 \\times 20262 \\times 0.5 * 4 = 821137812$ bytes of memory which translates to about $820$ megabytes of ram. This is no issue as any modern computer holds more than $10$ times that amount of memory, therefore we can keep the counts in RAM.\n",
        "\n",
        "But of course this method is not scalable. Imagine we were faced with twice the number of authors(~40k), which is quite reasonable. In that situation we would have required, around $3.2$ Gigabytes of RAM. For 80k authors, we would need $12.8$GB. As you can see, the amount of required RAM quickly gets out of control, therefore, instead of counting pair counts in main memory, we perform more than one pass over the data, and make smarter use of our memory."
      ],
      "metadata": {
        "id": "328mr9lqICDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A-priori Algorithm for frequent pair mining\n",
        "\n",
        "## Implementing 2 pass A-priori\n",
        "\n",
        "To find frequent co-authors we use the A-priori algorithm which consists of two passes over the entire dataset\n",
        " - pass 1: find frequent authors.\n",
        "  - the idea is by finding authors who haven't written a lot of papers, we can cross them out as candidates of being in a pair of frequent authors.\n",
        " -pass 2: count occurances of pairs of authors, only when each party is frequent by themselves.\n",
        "\n",
        "\n",
        "with this method we can find frequent pairs of authors, a generalisation of this approach is used to find larger frequent itemsets. But for now let us implement the simple variation of A-priori."
      ],
      "metadata": {
        "id": "Je0GWVqyKlCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass 1: count frequent authors\n",
        "\n",
        "# we use a dictionary to keep track of counts\n",
        "author_counts = {}\n",
        "\n",
        "with open('nips_authors_id.csv', 'r') as f:\n",
        "  reader = csv.reader(f, delimiter=',')\n",
        "  for row in reader:\n",
        "    for author_id in row[1:]:\n",
        "      # update counts dictionary\n",
        "      if author_id in author_counts:\n",
        "        author_counts[author_id] += 1\n",
        "      else:\n",
        "        author_counts[author_id] = 1"
      ],
      "metadata": {
        "id": "f-5U2qNvJond"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('number of unique authors: ',len(author_counts))\n",
        "print('each author published between 1 and', max(list(author_counts.values())), 'papers')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYHbcUth_rPF",
        "outputId": "b174b6b5-4355-46d9-d6d0-ea6809b4e6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique authors:  20263\n",
            "each author published between 1 and 79 papers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that no author has written more than 79 papers!\n",
        "\n",
        "We will use this fact later on."
      ],
      "metadata": {
        "id": "2QqvEu2fS78u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answering question 1\n",
        "\n",
        "Who are the most published NIPS authors and their publications?\n",
        "\n",
        "\n",
        "We will consider the the few authors with more than 50 published papers in NIPS,"
      ],
      "metadata": {
        "id": "y42LgXiCkpbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "select_authors = []\n",
        "\n",
        "# look for most frequent authors\n",
        "for k in author_counts:\n",
        "  if author_counts[k] > 50:\n",
        "    print(id_2_author[int(k)], author_counts[k])\n",
        "    select_authors.append(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6suw5WDlUz2b",
        "outputId": "90387dad-628b-41e0-f6e5-dc94e8118764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Michael Jordan 69\n",
            "Bernhard Schölkopf 79\n",
            "Tong Zhang 53\n",
            "Yoshua Bengio 71\n",
            "Francis Bach 67\n",
            "Russ R. Salakhutdinov 59\n",
            "Lawrence Carin 57\n",
            "Andreas Krause 55\n",
            "Sergey Levine 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# search for publications of the most published authors\n",
        "publications = {auth:[] for auth in select_authors}\n",
        "\n",
        "with open('nips_authors_id.csv', 'r') as f:\n",
        "  reader = csv.reader(f, delimiter=',')\n",
        "  for row in reader:\n",
        "    paper_id = row[0]\n",
        "    for author_id in row[1:]:\n",
        "      if author_id in publications:\n",
        "        publications[author_id].append(paper_id)"
      ],
      "metadata": {
        "id": "P9MziSY9VYTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for auth in publications:\n",
        "  print(id_2_author[int(auth)])\n",
        "  for paper in publications[auth]:\n",
        "    print(f'\\t{id_2_paper[int(paper)]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkIuruyhVYRg",
        "outputId": "d3a96040-ce31-4116-deff-659de277760a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Michael Jordan\n",
            "\t('Learning from Dyadic Data', '1998')\n",
            "\t('Approximate Inference A lgorithms for Two-Layer Bayesian Networks', '1999')\n",
            "\t('Latent Dirichlet Allocation', '2001')\n",
            "\t('Thin Junction Trees', '2001')\n",
            "\t('On Discriminative vs. Generative Classifiers: A comparison of logistic regression and naive Bayes', '2001')\n",
            "\t('On Spectral Clustering: Analysis and an algorithm', '2001')\n",
            "\t('Minimax Probability Machine', '2001')\n",
            "\t('Learning Graphical Models with Mercer Kernels', '2002')\n",
            "\t('A Minimal Intervention Principle for Coordinated Movement', '2002')\n",
            "\t('Distance Metric Learning with Application to Clustering with Side-Information', '2002')\n",
            "\t('A Hierarchical Bayesian Markovian Model for Motifs in Biopolymer Sequences', '2002')\n",
            "\t('Robust Novelty Detection with Single-Class MPM', '2002')\n",
            "\t('Statistical Debugging of Sampled Programs', '2003')\n",
            "\t('Semidefinite Relaxations for Approximate Inference on Graphs with Cycles', '2003')\n",
            "\t('Large Margin Classifiers: Convex Loss, Low Noise, and Convergence Rates', '2003')\n",
            "\t('Hierarchical Topic Models and the Nested Chinese Restaurant Process', '2003')\n",
            "\t('Kernel Dimensionality Reduction for Supervised Learning', '2003')\n",
            "\t('Autonomous Helicopter Flight via Reinforcement Learning', '2003')\n",
            "\t('Learning Spectral Clustering', '2003')\n",
            "\t('On the Concentration of Expectation and Approximate Inference in Layered Networks', '2003')\n",
            "\t('A Direct Formulation for Sparse PCA Using Semidefinite Programming', '2004')\n",
            "\t('Blind One-microphone Speech Separation: A Spectral Learning Approach', '2004')\n",
            "\t('Computing regularization paths for learning multiple kernels', '2004')\n",
            "\t('Semi-supervised Learning via Gaussian Processes', '2004')\n",
            "\t('Sharing Clusters among Related Groups: Hierarchical Dirichlet Processes', '2004')\n",
            "\t('Divergences, surrogate loss functions and experimental design', '2005')\n",
            "\t('Robust design of biological experiments', '2005')\n",
            "\t('Structured Prediction via the Extragradient Method', '2005')\n",
            "\t('In-Network PCA and Anomaly Detection', '2006')\n",
            "\t('Estimating divergence functionals and the likelihood ratio by penalized convex risk minimization', '2007')\n",
            "\t('Agreement-Based Learning', '2007')\n",
            "\t('Feature Selection Methods for Improving Protein Structure Prediction with Rosetta', '2007')\n",
            "\t('Efficient Inference in Phylogenetic InDel Trees', '2008')\n",
            "\t('Spectral Clustering with Perturbed Data', '2008')\n",
            "\t('High-dimensional support union recovery in multivariate regression', '2008')\n",
            "\t('DiscLDA: Discriminative Learning for Dimensionality Reduction and Classification', '2008')\n",
            "\t('Shared Segmentation of Natural Scenes Using Dependent Pitman-Yor Processes', '2008')\n",
            "\t('Posterior Consistency of the Silverman g-prior in Bayesian Model Choice', '2008')\n",
            "\t('Nonparametric Bayesian Learning of Switching Linear Dynamical Systems', '2008')\n",
            "\t('Nonparametric Latent Feature Models for Link Prediction', '2009')\n",
            "\t('Asymptotically Optimal Regularization in Smooth Parametric Models', '2009')\n",
            "\t('Sharing Features among Dynamical Systems with Beta Processes', '2009')\n",
            "\t('Random Conic Pursuit for Semidefinite Programming', '2010')\n",
            "\t('Heavy-Tailed Process Priors for Selective Shrinkage', '2010')\n",
            "\t('Tree-Structured Stick Breaking for Hierarchical Data', '2010')\n",
            "\t('Unsupervised Kernel Dimension Reduction', '2010')\n",
            "\t('Variational Inference over Combinatorial Spaces', '2010')\n",
            "\t('Bayesian Bias Mitigation for Crowdsourcing', '2011')\n",
            "\t('Divide-and-Conquer Matrix Factorization', '2011')\n",
            "\t('Privacy Aware Learning', '2012')\n",
            "\t('Small-Variance Asymptotics for Exponential Family Dirichlet Process Mixture Models', '2012')\n",
            "\t('Ancestor Sampling for Particle Gibbs', '2012')\n",
            "\t('Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods', '2012')\n",
            "\t('Decision-Making with Auto-Encoding Variational Bayes', '2020')\n",
            "\t('Robust Optimization for Fairness with Noisy Protected Groups', '2020')\n",
            "\t('Fixed-Support Wasserstein Barycenters: Computational Hardness and Fast Algorithm', '2020')\n",
            "\t('On the Theory of Transfer Learning: The Importance of Task Diversity', '2020')\n",
            "\t('Projection Robust Wasserstein Distance and Riemannian Optimization', '2020')\n",
            "\t('Provably Efficient Reinforcement Learning with Kernel and Neural Function Approximations', '2020')\n",
            "\t('Transferable Calibration with Lower Bias and Variance in Domain Adaptation', '2020')\n",
            "\t('On Component Interactions in Two-Stage Recommender Systems', '2021')\n",
            "\t('Learning Equilibria in Matching Markets from Bandit Feedback', '2021')\n",
            "\t('On the Theory of Reinforcement Learning with Once-per-Episode Feedback', '2021')\n",
            "\t('Learning in Multi-Stage Decentralized Matching Markets', '2021')\n",
            "\t('Tactical Optimism and Pessimism for Deep Reinforcement Learning', '2021')\n",
            "\t('Test-time Collective Prediction', '2021')\n",
            "\t('Who Leads and Who Follows in Strategic Classification?', '2021')\n",
            "\t('Wasserstein Flow Meets Replicator Dynamics: A Mean-Field Analysis of Representation Learning in Actor-Critic', '2021')\n",
            "\t('Robust Learning of Optimal Auctions', '2021')\n",
            "Bernhard Schölkopf\n",
            "\t('Kernel PCA and De-Noising in Feature Spaces', '1998')\n",
            "\t('Shrinking the Tube: A New Support Vector Regression Algorithm', '1998')\n",
            "\t('Semiparametric Support Vector and Linear Programming Machines', '1998')\n",
            "\t('The Entropy Regularization Information Criterion', '1999')\n",
            "\t('Invariant Feature Extraction and Classification in Kernel Spaces', '1999')\n",
            "\t('v-Arc: Ensemble Learning in the Presence of Outliers', '1999')\n",
            "\t('Support Vector Method for Novelty Detection', '1999')\n",
            "\t('Four-legged Walking Gait Control Using a Neuromorphic Chip Interfaced to a Support Vector Learning Algorithm', '2000')\n",
            "\t('The Kernel Trick for Distances', '2000')\n",
            "\t('Support Vector Novelty Detection Applied to Jet Engine Vibration Spectra', '2000')\n",
            "\t('Incorporating Invariances in Non-Linear Support Vector Machines', '2001')\n",
            "\t('Sampling Techniques for Kernel Methods', '2001')\n",
            "\t('Cluster Kernels for Semi-Supervised Learning', '2002')\n",
            "\t('Kernel Dependency Estimation', '2002')\n",
            "\t('Ranking on Data Manifolds', '2003')\n",
            "\t('Learning with Local and Global Consistency', '2003')\n",
            "\t('Learning to Find Pre-Images', '2003')\n",
            "\t('Prediction on Spike Data Using Kernel Algorithms', '2003')\n",
            "\t('Machine Learning Applied to Perception: Decision Images for Gender Classification', '2004')\n",
            "\t('Implicit Wiener Series for Higher-Order Image Analysis', '2004')\n",
            "\t('Kernel Methods for Implicit Surface Modeling', '2004')\n",
            "\t('An Auditory Paradigm for Brain-Computer Interfaces', '2004')\n",
            "\t('Methods Towards Invasive Human Brain Computer Interfaces', '2004')\n",
            "\t('Semi-supervised Learning on Directed Graphs', '2004')\n",
            "\t('Face Detection --- Efficient and Rank Deficient', '2004')\n",
            "\t('A Local Learning Approach for Clustering', '2006')\n",
            "\t('Implicit Surfaces with Globally Regularised and Compactly Supported Basis Functions', '2006')\n",
            "\t('Correcting Sample Selection Bias by Unlabeled Data', '2006')\n",
            "\t('A Nonparametric Approach to Bottom-Up Visual Saliency', '2006')\n",
            "\t('Learning with Hypergraphs: Clustering, Classification, and Embedding', '2006')\n",
            "\t('Learning Dense 3D Correspondence', '2006')\n",
            "\t('A Kernel Method for the Two-Sample-Problem', '2006')\n",
            "\t('Kernel Measures of Conditional Dependence', '2007')\n",
            "\t('An Analysis of Inference with the Universum', '2007')\n",
            "\t('A Kernel Statistical Test of Independence', '2007')\n",
            "\t('An Empirical Analysis of Domain Adaptation Algorithms for Genomic Sequence Analysis', '2008')\n",
            "\t('Diffeomorphic Dimensionality Reduction', '2008')\n",
            "\t('Effects of Stimulus Type and of Error-Correcting Code Design on BCI Speller Performance', '2008')\n",
            "\t('Bayesian Experimental Design of Magnetic Resonance Imaging Sequences', '2008')\n",
            "\t('Characteristic Kernels on Groups and Semigroups', '2008')\n",
            "\t('Nonlinear causal discovery with additive noise models', '2008')\n",
            "\t('Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions', '2009')\n",
            "\t('Switched Latent Force Models for Movement Segmentation', '2010')\n",
            "\t('Space-Variant Single-Image Blind Deconvolution for Removing Camera Shake', '2010')\n",
            "\t('Probabilistic latent variable models for distinguishing between cause and effect', '2010')\n",
            "\t('Recovering Intrinsic Images with a Global Sparsity Prior on Reflectance', '2011')\n",
            "\t('On Causal Discovery with Cyclic Additive Noise Models', '2011')\n",
            "\t('Semi-Supervised Domain Adaptation with Non-Parametric Copulas', '2012')\n",
            "\t('Learning from Distributions via Support Measure Machines', '2012')\n",
            "\t('The representer theorem for Hilbert spaces: a necessary and sufficient condition', '2012')\n",
            "\t('Causal Inference on Time Series using Restricted Structural Equation Models', '2013')\n",
            "\t('The Randomized Dependence Coefficient', '2013')\n",
            "\t('Statistical analysis of coupled time series with Kernel Cross-Spectral Density operators.', '2013')\n",
            "\t('Kernel Mean Estimation via Spectral Filtering', '2014')\n",
            "\t('Consistent Kernel Mean Estimation for Functions of Random Variables', '2016')\n",
            "\t('Minimax Estimation of Maximum Mean Discrepancy with Radial Kernels', '2016')\n",
            "\t('Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning', '2017')\n",
            "\t('AdaGAN: Boosting Generative Models', '2017')\n",
            "\t('Avoiding Discrimination through Causal Reasoning', '2017')\n",
            "\t('Adaptive Skip Intervals: Temporal Abstraction for Recurrent Dynamical Models', '2018')\n",
            "\t('Informative Features for Model Comparison', '2018')\n",
            "\t('On the Fairness of Disentangled Representations', '2019')\n",
            "\t('Perceiving the arrow of time in autoregressive motion', '2019')\n",
            "\t('Kernel Stein Tests for Multiple Model Comparison', '2019')\n",
            "\t('On the Transfer of Inductive Bias from Simulation to the Real World: a New Disentanglement Dataset', '2019')\n",
            "\t('Selecting causal brain features with a single conditional independence test per feature', '2019')\n",
            "\t('Algorithmic recourse under imperfect causal knowledge: a probabilistic approach', '2020')\n",
            "\t('Causal analysis of Covid-19 Spread in Germany', '2020')\n",
            "\t('Learning Kernel Tests Without Data Splitting', '2020')\n",
            "\t('Relative gradient optimization of the Jacobian term in unsupervised deep learning', '2020')\n",
            "\t('Backward-Compatible Prediction Updates: A Probabilistic Approach', '2021')\n",
            "\t('Regret Bounds for Gaussian-Process Optimization in Large Domains', '2021')\n",
            "\t('Dynamic Inference with Neural Interpreters', '2021')\n",
            "\t('The Inductive Bias of Quantum Kernels', '2021')\n",
            "\t('Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style', '2021')\n",
            "\t('Iterative Teaching by Label Synthesis', '2021')\n",
            "\t('Causal Influence Detection for Improving Efficiency in Reinforcement Learning', '2021')\n",
            "\t('DiBS: Differentiable Bayesian Structure Learning', '2021')\n",
            "\t('Independent mechanism analysis, a new concept?', '2021')\n",
            "Tong Zhang\n",
            "\t('Some Theoretical Results Concerning the Convergence of Compositions of Regularized Linear Functions', '1999')\n",
            "\t('Convergence of Large Margin Separable Linear Classification', '2000')\n",
            "\t('Regularized Winnow Methods', '2000')\n",
            "\t('Effective Dimension and Generalization of Kernel Learning', '2002')\n",
            "\t('Data-Dependent Bounds for Bayesian Mixture Methods', '2002')\n",
            "\t('An Infinity-sample Theory for Multi-category Large Margin Classification', '2003')\n",
            "\t('Learning Bounds for a Generalized Family of Bayesian Posterior Distributions', '2003')\n",
            "\t('Support Vector Classification with Input Data Uncertainty', '2004')\n",
            "\t('Class-size Independent Generalization Analsysis of Some Discriminative Multi-Category Classification', '2004')\n",
            "\t('Analysis of Spectral Kernel Design based Semi-supervised Learning', '2005')\n",
            "\t('Learning on Graph with Laplacian Regularization', '2006')\n",
            "\t('The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information', '2007')\n",
            "\t('A General Boosting Method and its Application to Learning Ranking Functions for Web Search', '2007')\n",
            "\t('Multi-stage Convex Relaxation for Learning with Sparse Regularization', '2008')\n",
            "\t('Adaptive Forward-Backward Greedy Algorithm for Sparse Learning with Linear Models', '2008')\n",
            "\t('Sparse Online Learning via Truncated Gradient', '2008')\n",
            "\t('Nonlinear Learning using Local Coordinate Coding', '2009')\n",
            "\t('Multi-Label Prediction via Compressed Sensing', '2009')\n",
            "\t('Agnostic Active Learning Without Constraints', '2010')\n",
            "\t('Deep Coding Network', '2010')\n",
            "\t('Spectral Methods for Learning Multivariate Latent Tree Structure', '2011')\n",
            "\t('Greedy Model Averaging', '2011')\n",
            "\t('Learning to Search Efficiently in High Dimensions', '2011')\n",
            "\t('Selective Labeling via Error Bound Minimization', '2012')\n",
            "\t('Accelerated Mini-Batch Stochastic Dual Coordinate Ascent', '2013')\n",
            "\t('Accelerating Stochastic Gradient Descent using Predictive Variance Reduction', '2013')\n",
            "\t('Quartz: Randomized Dual Coordinate Ascent with Arbitrary Sampling', '2015')\n",
            "\t('Local Smoothness in Variance Reduced Optimization', '2015')\n",
            "\t('Semi-supervised Convolutional Neural Networks for Text Categorization via Region Embedding', '2015')\n",
            "\t('Exact Recovery of Hard Thresholding Pursuit', '2016')\n",
            "\t('Learning Additive Exponential Family Graphical Models via $\\\\ell_{2,1}$-norm Regularized M-Estimation', '2016')\n",
            "\t('Diffusion Approximations for Online Principal Component Estimation and Global Convergence', '2017')\n",
            "\t('On Quadratic Convergence of DC Proximal Newton Algorithm in Nonconvex Sparse Learning', '2017')\n",
            "\t('Efficient Optimization for Linear Dynamical Systems with Applications to Clustering and Sparse Coding', '2017')\n",
            "\t('Deep Subspace Clustering Networks', '2017')\n",
            "\t('Adaptive Sampling Towards Fast Graph Representation Learning', '2018')\n",
            "\t('Stochastic Primal-Dual Method for Empirical Risk Minimization with O(1) Per-Iteration Complexity', '2018')\n",
            "\t('SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator', '2018')\n",
            "\t('Gradient Sparsification for Communication-Efficient Distributed Optimization', '2018')\n",
            "\t('Communication Compression for Decentralized Training', '2018')\n",
            "\t('Exponentially Weighted Imitation Learning for Batched Historical Data', '2018')\n",
            "\t('Stochastic Expectation Maximization with Variance Reduction', '2018')\n",
            "\t('Divergence-Augmented Policy Optimization', '2019')\n",
            "\t('Bridging the Gap between Sample-based and One-shot Neural Architecture Search with BONAS', '2020')\n",
            "\t('How to Characterize The Landscape of Overparameterized Convolutional Neural Networks', '2020')\n",
            "\t('Residual Distillation: Towards Portable Deep Neural Networks without Shortcuts', '2020')\n",
            "\t('A Generalized Neural Tangent Kernel Analysis for Two-layer Neural Networks', '2020')\n",
            "\t('Decentralized Accelerated Proximal Gradient Descent', '2020')\n",
            "\t('Model Rubik’s Cube: Twisting Resolution, Depth and Width for TinyNets', '2020')\n",
            "\t('Stochastic Recursive Gradient Descent Ascent for Stochastic Nonconvex-Strongly-Concave Minimax Problems', '2020')\n",
            "\t('A Provably Efficient Model-Free Posterior Sampling Method for Episodic Reinforcement Learning', '2021')\n",
            "\t('Efficient Neural Network Training via Forward and Backward Propagation Sparsification', '2021')\n",
            "\t('Error Compensated Distributed SGD Can Be Accelerated', '2021')\n",
            "Yoshua Bengio\n",
            "\t('Inference for the Generalization Error', '1999')\n",
            "\t('Modeling High-Dimensional Discrete Data with Multi-Layer Neural Networks', '1999')\n",
            "\t('Incorporating Second-Order Functional Knowledge for Better Option Pricing', '2000')\n",
            "\t('A Neural Probabilistic Language Model', '2000')\n",
            "\t('K-Local Hyperplane and Convex Distance Nearest Neighbor Algorithms', '2001')\n",
            "\t('Estimating Car Insurance Premia: a Case Study in High-Dimensional Data Inference', '2001')\n",
            "\t('A Parallel Mixture of SVMs for Very Large Scale Problems', '2001')\n",
            "\t('Manifold Parzen Windows', '2002')\n",
            "\t('Out-of-Sample Extensions for LLE, Isomap, MDS, Eigenmaps, and Spectral Clustering', '2003')\n",
            "\t('No Unbiased Estimator of the Variance of K-Fold Cross-Validation', '2003')\n",
            "\t('Non-Local Manifold Tangent Learning', '2004')\n",
            "\t('Semi-supervised Learning by Entropy Minimization', '2004')\n",
            "\t('Brain Inspired Reinforcement Learning', '2004')\n",
            "\t('Convex Neural Networks', '2005')\n",
            "\t('Non-Local Manifold Parzen Windows', '2005')\n",
            "\t('The Curse of Highly Variable Functions for Local Kernel Machines', '2005')\n",
            "\t('Greedy Layer-Wise Training of Deep Networks', '2006')\n",
            "\t('Learning the 2-D Topology of Images', '2007')\n",
            "\t('Augmented Functional Time Series Representation and Forecasting with Gaussian Processes', '2007')\n",
            "\t('Topmoumoute Online Natural Gradient Algorithm', '2007')\n",
            "\t('Slow, Decorrelated Features for Pretraining Complex Cell-like Networks', '2009')\n",
            "\t('An Infinite Factor Model Hierarchy Via a Noisy-Or Mechanism', '2009')\n",
            "\t('On Tracking The Partition Function', '2011')\n",
            "\t('Algorithms for Hyper-Parameter Optimization', '2011')\n",
            "\t('Shallow vs. Deep Sum-Product Networks', '2011')\n",
            "\t('The Manifold Tangent Classifier', '2011')\n",
            "\t('Multi-Prediction Deep Boltzmann Machines', '2013')\n",
            "\t('Generalized Denoising Auto-Encoders as Generative Models', '2013')\n",
            "\t('Stochastic Ratio Matching of RBMs for Sparse High-Dimensional Inputs', '2013')\n",
            "\t('On the Number of Linear Regions of Deep Neural Networks', '2014')\n",
            "\t('Identifying and attacking the saddle point problem in high-dimensional non-convex optimization', '2014')\n",
            "\t('How transferable are features in deep neural networks?', '2014')\n",
            "\t('Iterative Neural Autoregressive Distribution Estimator NADE-k', '2014')\n",
            "\t('Generative Adversarial Nets', '2014')\n",
            "\t('Attention-Based Models for Speech Recognition', '2015')\n",
            "\t('BinaryConnect: Training Deep Neural Networks with binary weights during propagations', '2015')\n",
            "\t('Equilibrated adaptive learning rates for non-convex optimization', '2015')\n",
            "\t('A Recurrent Latent Variable Model for Sequential Data', '2015')\n",
            "\t('Professor Forcing: A New Algorithm for Training Recurrent Networks', '2016')\n",
            "\t('Architectural Complexity Measures of Recurrent Neural Networks', '2016')\n",
            "\t('Binarized Neural Networks', '2016')\n",
            "\t('On Multiplicative Integration with Recurrent Neural Networks', '2016')\n",
            "\t('GibbsNet: Iterative Adversarial Inference for Deep Graphical Models', '2017')\n",
            "\t('Variational Walkback: Learning a Transition Operator as a Stochastic Recurrent Net', '2017')\n",
            "\t('Z-Forcing: Training Stochastic Recurrent Networks', '2017')\n",
            "\t('Plan, Attend, Generate: Planning for Sequence-to-Sequence Models', '2017')\n",
            "\t('Dendritic cortical microcircuits approximate the backpropagation algorithm', '2018')\n",
            "\t('MetaGAN: An Adversarial Approach to Few-Shot Learning', '2018')\n",
            "\t('Image-to-image translation for cross-domain disentanglement', '2018')\n",
            "\t('Bayesian Model-Agnostic Meta-Learning', '2018')\n",
            "\t('Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding', '2018')\n",
            "\t('Updates of Equilibrium Prop Match Gradients of Backprop Through Time in an RNN with Static Input', '2019')\n",
            "\t('MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis', '2019')\n",
            "\t('Unsupervised State Representation Learning in Atari', '2019')\n",
            "\t('Non-normal Recurrent Neural Network (nnRNN): learning long time dependencies while improving expressivity with transient dynamics', '2019')\n",
            "\t('Variational Temporal Abstraction', '2019')\n",
            "\t('How to Initialize your Network? Robust Initialization for WeightNorm & ResNets', '2019')\n",
            "\t('Gradient based sample selection for online continual learning', '2019')\n",
            "\t('On Adversarial Mixup Resynthesis', '2019')\n",
            "\t('Wasserstein Dependency Measure for Representation Learning', '2019')\n",
            "\t('Your GAN is Secretly an Energy-based Model and You Should Use Discriminator Driven Latent Sampling', '2020')\n",
            "\t('Hybrid Models for Learning to Branch', '2020')\n",
            "\t('Untangling tradeoffs between recurrence and self-attention in artificial neural networks', '2020')\n",
            "\t('Gradient Starvation: A Learning Proclivity in Neural Networks', '2021')\n",
            "\t('A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning', '2021')\n",
            "\t('Discrete-Valued Neural Communication', '2021')\n",
            "\t('Invariance Principle Meets Information Bottleneck for Out-of-Distribution Generalization', '2021')\n",
            "\t('The Causal-Neural Connection: Expressiveness, Learnability, and Inference', '2021')\n",
            "\t('Dynamic Inference with Neural Interpreters', '2021')\n",
            "\t('Neural Production Systems', '2021')\n",
            "\t('Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation', '2021')\n",
            "Francis Bach\n",
            "\t('Thin Junction Trees', '2001')\n",
            "\t('Learning Graphical Models with Mercer Kernels', '2002')\n",
            "\t('Kernel Dimensionality Reduction for Supervised Learning', '2003')\n",
            "\t('Learning Spectral Clustering', '2003')\n",
            "\t('Blind One-microphone Speech Separation: A Spectral Learning Approach', '2004')\n",
            "\t('Computing regularization paths for learning multiple kernels', '2004')\n",
            "\t('Statistical Convergence of Kernel CCA', '2005')\n",
            "\t('Active learning for misspecified generalized linear models', '2006')\n",
            "\t('DIFFRAC: a discriminative and flexible framework for clustering', '2007')\n",
            "\t('Testing for Homogeneity with Kernel Fisher Discriminant Analysis', '2007')\n",
            "\t('Kernel Change-point Analysis', '2008')\n",
            "\t('Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning', '2008')\n",
            "\t('Supervised Dictionary Learning', '2008')\n",
            "\t('Sparse probabilistic projections', '2008')\n",
            "\t('Clustered Multi-Task Learning: A Convex Formulation', '2008')\n",
            "\t('Asymptotically Optimal Regularization in Smooth Parametric Models', '2009')\n",
            "\t('Data-driven calibration of linear estimators with minimal penalties', '2009')\n",
            "\t('Structured sparsity-inducing norms through submodular functions', '2010')\n",
            "\t('Efficient Optimization for Discriminative Latent Class Models', '2010')\n",
            "\t('Network Flow Algorithms for Structured Sparsity', '2010')\n",
            "\t('Online Learning for Latent Dirichlet Allocation', '2010')\n",
            "\t('Trace Lasso: a trace norm regularization for correlated designs', '2011')\n",
            "\t('Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning', '2011')\n",
            "\t('Convergence Rates of Inexact Proximal-Gradient Methods for Convex Optimization', '2011')\n",
            "\t('Shaping Level Sets with Submodular Functions', '2011')\n",
            "\t('Multiple Operator-valued Kernel Learning', '2012')\n",
            "\t('A Stochastic Gradient Method with an Exponential Convergence _Rate for Finite Training Sets', '2012')\n",
            "\t('Reflection methods for user-friendly submodular optimization', '2013')\n",
            "\t('Convex Relaxations for Permutation Problems', '2013')\n",
            "\t('Non-strongly-convex smooth stochastic approximation with convergence rate O(1/n)', '2013')\n",
            "\t('Metric Learning for Temporal Sequence Alignment', '2014')\n",
            "\t('SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives', '2014')\n",
            "\t('Spectral Norm Regularization of Orthonormal Representations for Graph Transduction', '2015')\n",
            "\t('Rethinking LDA: Moment Matching for Discrete ICA', '2015')\n",
            "\t('Stochastic Variance Reduction Methods for Saddle-Point Problems', '2016')\n",
            "\t('Stochastic Optimization for Large-scale Optimal Transport', '2016')\n",
            "\t('PAC-Bayesian Theory Meets Bayesian Inference', '2016')\n",
            "\t('Regularized Nonlinear Acceleration', '2016')\n",
            "\t('Parameter Learning for Log-supermodular Distributions', '2016')\n",
            "\t('On Structured Prediction Theory with Calibrated Convex Surrogate Losses', '2017')\n",
            "\t('Integration Methods and Optimization Algorithms', '2017')\n",
            "\t('Nonlinear Acceleration of Stochastic Algorithms', '2017')\n",
            "\t('Statistical Optimality of Stochastic Gradient Descent on Hard Learning Problems through Multiple Passes', '2018')\n",
            "\t(\"Rest-Katyusha: Exploiting the Solution's Structure via Scheduled Restart Schemes\", '2018')\n",
            "\t('SING: Symbol-to-Instrument Neural Generator', '2018')\n",
            "\t('Efficient Algorithms for Non-convex Isotonic Regression through Submodular Optimization', '2018')\n",
            "\t('Optimal Algorithms for Non-Smooth Distributed Optimization in Networks', '2018')\n",
            "\t('On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport', '2018')\n",
            "\t('Relating Leverage Scores and Density using Regularized Christoffel Functions', '2018')\n",
            "\t('Localized Structured Prediction', '2019')\n",
            "\t('An Accelerated Decentralized Stochastic Proximal Algorithm for Finite Sums', '2019')\n",
            "\t('Globally Convergent Newton Methods for Ill-conditioned Generalized Self-concordant Losses', '2019')\n",
            "\t('UniXGrad: A Universal, Adaptive Algorithm with Optimal Guarantees for Constrained Optimization', '2019')\n",
            "\t('Partially Encrypted Deep Learning using Functional Encryption', '2019')\n",
            "\t('On Lazy Training in Differentiable Programming', '2019')\n",
            "\t('Towards closing the gap between the theory and practice of SVRG', '2019')\n",
            "\t('Fast Decomposable Submodular Function Minimization using Constrained Total Variation', '2019')\n",
            "\t('Implicit Regularization of Discrete Gradient Dynamics in Linear Neural Networks', '2019')\n",
            "\t('Massively scalable Sinkhorn distances via the Nyström method', '2019')\n",
            "\t('Tight Nonparametric Convergence Rates for Stochastic Gradient Descent under the Noiseless Linear Model', '2020')\n",
            "\t('Learning with Differentiable Pertubed Optimizers', '2020')\n",
            "\t('Non-parametric Models for Non-negative Functions', '2020')\n",
            "\t('Batch normalization provably avoids ranks collapse for randomly initialised deep networks', '2020')\n",
            "\t('Dual-Free Stochastic Decentralized Optimization with Variance Reduction', '2020')\n",
            "\t('Batch Normalization Orthogonalizes Representations in Deep Random Networks', '2021')\n",
            "\t('Continuized Accelerations of Deterministic and Stochastic Gradient Descents, and of Gossip Algorithms', '2021')\n",
            "\t('Overcoming the curse of dimensionality with Laplacian regularization in semi-supervised learning', '2021')\n",
            "Russ R. Salakhutdinov\n",
            "\t('Neighbourhood Components Analysis', '2004')\n",
            "\t('Using Deep Belief Nets to Learn Covariance Kernels for Gaussian Processes', '2007')\n",
            "\t('Probabilistic Matrix Factorization', '2007')\n",
            "\t('Evaluating probabilities under high-dimensional latent variable models', '2008')\n",
            "\t('Replicated Softmax: an Undirected Topic Model', '2009')\n",
            "\t('Modelling Relational Data using Bayesian Clustered Tensor Factorization', '2009')\n",
            "\t('Learning in Markov Random Fields using Tempered Transitions', '2009')\n",
            "\t('Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm', '2010')\n",
            "\t('Practical Large-Scale Optimization for Max-norm Regularization', '2010')\n",
            "\t('Learning to Learn with Compound HD Models', '2011')\n",
            "\t('Transfer Learning by Borrowing Examples for Multiclass Object Detection', '2011')\n",
            "\t('Learning with the weighted trace-norm under arbitrary sampling distributions', '2011')\n",
            "\t('Hamming Distance Metric Learning', '2012')\n",
            "\t('A Better Way to Pretrain Deep Boltzmann Machines', '2012')\n",
            "\t('Cardinality Restricted Boltzmann Machines', '2012')\n",
            "\t('Multimodal Learning with Deep Boltzmann Machines', '2012')\n",
            "\t('Matrix reconstruction with the local max norm', '2012')\n",
            "\t('One-shot learning by inverting a compositional causal process', '2013')\n",
            "\t('The Power of Asymmetry in Binary Hashing', '2013')\n",
            "\t('Discriminative Transfer Learning with Tree-based Priors', '2013')\n",
            "\t('Learning Stochastic Feedforward Neural Networks', '2013')\n",
            "\t('Annealing between distributions by averaging moments', '2013')\n",
            "\t('Learning Generative Models with Visual Attention', '2014')\n",
            "\t('A Multiplicative Model for Learning Distributed Text-Based Attribute Representations', '2014')\n",
            "\t('Learning Wake-Sleep Recurrent Attention Models', '2015')\n",
            "\t('Path-SGD: Path-Normalized Optimization in Deep Neural Networks', '2015')\n",
            "\t('Skip-Thought Vectors', '2015')\n",
            "\t('Iterative Refinement of the Approximate Posterior for Directed Belief Networks', '2016')\n",
            "\t('Path-Normalized Optimization of Recurrent Neural Networks with ReLU Activations', '2016')\n",
            "\t('Architectural Complexity Measures of Recurrent Neural Networks', '2016')\n",
            "\t('Review Networks for Caption Generation', '2016')\n",
            "\t('Stochastic Variational Deep Kernel Learning', '2016')\n",
            "\t('On Multiplicative Integration with Recurrent Neural Networks', '2016')\n",
            "\t('Good Semi-supervised Learning That Requires a Bad GAN', '2017')\n",
            "\t('Deep Sets', '2017')\n",
            "\t('How Many Samples are Needed to Estimate a Convolutional Neural Network?', '2018')\n",
            "\t('GLoMo: Unsupervised Learning of Transferable Relational Graphs', '2018')\n",
            "\t('Deep Generative Models with Learnable Knowledge Constraints', '2018')\n",
            "\t('Deep Gamblers: Learning to Abstain with Portfolio Theory', '2019')\n",
            "\t('Learning Neural Networks with Adaptive Regularization', '2019')\n",
            "\t('Mixtape: Breaking the Softmax Bottleneck Efficiently', '2019')\n",
            "\t('Search on the Replay Buffer: Bridging Planning and Reinforcement Learning', '2019')\n",
            "\t('Graph Neural Tangent Kernel: Fusing Graph Neural Networks with Graph Kernels', '2019')\n",
            "\t('Learning Data Manipulation for Augmentation and Weighting', '2019')\n",
            "\t('Multiple Futures Prediction', '2019')\n",
            "\t('On Exact Computation with an Infinitely Wide Neural Net', '2019')\n",
            "\t('XLNet: Generalized Autoregressive Pretraining for Language Understanding', '2019')\n",
            "\t('Neural Methods for Point-wise Dependency Estimation', '2020')\n",
            "\t('Weakly-Supervised Reinforcement Learning for Controllable Behavior', '2020')\n",
            "\t('Object Goal Navigation using Goal-Oriented Semantic Exploration', '2020')\n",
            "\t('Reinforcement Learning with General Value Function Approximation: Provably Efficient Approach via Bounded Eluder Dimension', '2020')\n",
            "\t('A Closer Look at Accuracy vs. Robustness', '2020')\n",
            "\t('Planning with General Objective Functions: Going Beyond Total Rewards', '2020')\n",
            "\t('Rewriting History with Inverse RL: Hindsight Inference for Policy Improvement', '2020')\n",
            "\t('On Reward-Free Reinforcement Learning with Linear Function Approximation', '2020')\n",
            "\t('Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification', '2021')\n",
            "\t('SEAL: Self-supervised Embodied Active Learning using Exploration and 3D Consistency', '2021')\n",
            "\t('Accelerating Robotic Reinforcement Learning via Parameterized Action Primitives', '2021')\n",
            "\t('Robust Predictable Control', '2021')\n",
            "Lawrence Carin\n",
            "\t('On Semi-Supervised Classification', '2004')\n",
            "\t('Radial Basis Function Network for Multi-task Learning', '2005')\n",
            "\t('Semi-Supervised Multitask Learning', '2007')\n",
            "\t('Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations', '2009')\n",
            "\t('Learning to Explore and Exploit in POMDPs', '2009')\n",
            "\t('A Bayesian Model for Simultaneous Image Clustering, Annotation and Object Segmentation', '2009')\n",
            "\t('Joint Analysis of Time-Evolving Binary Matrices and Associated Documents', '2010')\n",
            "\t('The Kernel Beta Process', '2011')\n",
            "\t('On the Analysis of Multi-Channel Neural Spike Data', '2011')\n",
            "\t('Hierarchical Topic Modeling for Analysis of Time-Evolving Personal Choices', '2011')\n",
            "\t('Augment-and-Conquer Negative Binomial Processes', '2012')\n",
            "\t('Joint Modeling of a Matrix with Associated Text via Latent Binary Features', '2012')\n",
            "\t('Integrated Non-Factorized Variational Inference', '2013')\n",
            "\t('Dynamic Clustering via Asymptotics of the Dependent Dirichlet Process Mixture', '2013')\n",
            "\t('Real-Time Inference for a Gamma Process Model of Neural Spiking', '2013')\n",
            "\t('Designed Measurements for Vector Count Data', '2013')\n",
            "\t('Compressive Sensing of Signals from a GMM with Sparse Precision Matrices', '2014')\n",
            "\t('On the relations of LFPs & Neural Spike Trains', '2014')\n",
            "\t('Bayesian Nonlinear Support Vector Machines and Discriminative Factor Modeling', '2014')\n",
            "\t('Dynamic Rank Factor Model for Text Streams', '2014')\n",
            "\t('Analysis of Brain States from Multi-Region LFP Time-Series', '2014')\n",
            "\t('GP Kernels for Cross-Spectrum Analysis', '2015')\n",
            "\t('Large-Scale Bayesian Multi-Label Learning via Topic-Based Label Embeddings', '2015')\n",
            "\t('Deep Temporal Sigmoid Belief Networks for Sequence Modeling', '2015')\n",
            "\t('On the Convergence of Stochastic Gradient MCMC Algorithms with High-Order Integrators', '2015')\n",
            "\t('Deep Poisson Factor Modeling', '2015')\n",
            "\t('Preconditioned Spectral Descent for Deep Learning', '2015')\n",
            "\t('Towards Unifying Hamiltonian Monte Carlo and Slice Sampling', '2016')\n",
            "\t('Linear Feature Encoding for Reinforcement Learning', '2016')\n",
            "\t('Stochastic Gradient MCMC with Stale Gradients', '2016')\n",
            "\t('Variational Autoencoder for Deep Learning of Images, Labels and Captions', '2016')\n",
            "\t('A Probabilistic Framework for Nonlinearities in Stochastic Neural Networks', '2017')\n",
            "\t('VAE Learning via Stein Variational Gradient Descent', '2017')\n",
            "\t('Deconvolutional Paragraph Representation Learning', '2017')\n",
            "\t('Adversarial Symmetric Variational Autoencoder', '2017')\n",
            "\t('Cross-Spectral Factor Analysis', '2017')\n",
            "\t('Targeting EEG/LFP Synchrony with Neural Nets', '2017')\n",
            "\t('Scalable Model Selection for Belief Networks', '2017')\n",
            "\t('ALICE: Towards Understanding Adversarial Learning for Joint Distribution Matching', '2017')\n",
            "\t('Triangle Generative Adversarial Networks', '2017')\n",
            "\t('An inner-loop free solution to inverse problems using deep neural networks', '2017')\n",
            "\t(\"Adversarial Text Generation via Feature-Mover's Distance\", '2018')\n",
            "\t('Diffusion Maps for Textual Network Embedding', '2018')\n",
            "\t('Distilled Wasserstein Learning for Word Embedding and Topic Modeling', '2018')\n",
            "\t('Ouroboros: On Accelerating Training of Transformer-Based Language Models', '2019')\n",
            "\t('Certified Adversarial Robustness with Additive Noise', '2019')\n",
            "\t('Improving Textual Network Learning with Variational Homophilic Embeddings', '2019')\n",
            "\t('On Fenchel Mini-Max Learning', '2019')\n",
            "\t('Scalable Gromov-Wasserstein Learning for Graph Partitioning and Matching', '2019')\n",
            "\t('Kernel-Based Approaches for Sequence Modeling: Connections to Neural Methods', '2019')\n",
            "\t('AutoSync: Learning to Synchronize for Data-Parallel Distributed Deep Learning', '2020')\n",
            "\t('Calibrating CNNs for Lifelong Learning', '2020')\n",
            "\t('GAN Memory with No Forgetting', '2020')\n",
            "\t('Perturbing Across the Feature Hierarchy to Improve Standard and Strict Blackbox Attack Transferability', '2020')\n",
            "\t('Reconsidering Generative Objectives For Counterfactual Reasoning', '2020')\n",
            "\t('CAM-GAN: Continual Adaptation Modules for Generative Adversarial Networks', '2021')\n",
            "\t('Supercharging Imbalanced Data Learning With Energy-based Contrastive Representation Transfer', '2021')\n",
            "Andreas Krause\n",
            "\t('Selecting Observations against Adversarial Objectives', '2007')\n",
            "\t('Online Learning of Assignments', '2009')\n",
            "\t('Near-Optimal Bayesian Active Learning with Noisy Observations', '2010')\n",
            "\t('Discriminative Clustering by Regularized Information Maximization', '2010')\n",
            "\t('Efficient Minimization of Decomposable Submodular Functions', '2010')\n",
            "\t('Scalable Training of Mixture Models via Coresets', '2011')\n",
            "\t('Crowdclustering', '2011')\n",
            "\t('Contextual Gaussian Process Bandit Optimization', '2011')\n",
            "\t('Distributed Submodular Maximization: Identifying Representative Elements in Massive Data', '2013')\n",
            "\t('High-Dimensional Gaussian Process Bandits', '2013')\n",
            "\t('Efficient Partial Monitoring with Prior Information', '2014')\n",
            "\t('Efficient Sampling for Learning Sparse Additive Models in High Dimensions', '2014')\n",
            "\t('From MAP to Marginals: Variational Inference in Bayesian Submodular Models', '2014')\n",
            "\t('Sampling from Probabilistic Submodular Models', '2015')\n",
            "\t('Distributed Submodular Cover: Succinctly Summarizing Massive Data', '2015')\n",
            "\t('Cooperative Graphical Models', '2016')\n",
            "\t('Variational Inference in Mixed Probabilistic Submodular Models', '2016')\n",
            "\t('Safe Exploration in Finite Markov Decision Processes with Gaussian Processes', '2016')\n",
            "\t('Truncated Variance Reduction: A Unified Approach to Bayesian Optimization and Level-Set Estimation', '2016')\n",
            "\t('Fast and Provably Good Seedings for k-Means', '2016')\n",
            "\t('Differentiable Learning of Submodular Models', '2017')\n",
            "\t('Continuous DR-submodular  Maximization: Structure and Algorithms', '2017')\n",
            "\t('Safe Model-based Reinforcement Learning with Stability Guarantees', '2017')\n",
            "\t('Stochastic Submodular Maximization: The Case of Coverage Functions', '2017')\n",
            "\t('Interactive Submodular Bandit', '2017')\n",
            "\t('Provable Variational Inference for Constrained Log-Submodular Models', '2018')\n",
            "\t('Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features', '2018')\n",
            "\t('Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making', '2018')\n",
            "\t('Teaching Multiple Concepts to a Forgetful Learner', '2019')\n",
            "\t('Adaptive Sequence Submodularity', '2019')\n",
            "\t('Safe Exploration for Interactive Machine Learning', '2019')\n",
            "\t('No-Regret Learning in Unknown Games with Correlated Payoffs', '2019')\n",
            "\t('A Domain Agnostic Measure for Monitoring and Evaluating GANs', '2019')\n",
            "\t('Stochastic Bandits with Context Distributions', '2019')\n",
            "\t('Efficiently Learning Fourier Sparse Set Functions', '2019')\n",
            "\t('Adaptive Sampling for Stochastic Risk-Averse Learning', '2020')\n",
            "\t('Gradient Estimation with Stochastic Softmax Tricks', '2020')\n",
            "\t('Learning to Play Sequential Games versus Unknown Opponents', '2020')\n",
            "\t('Safe Reinforcement Learning via Curriculum Induction', '2020')\n",
            "\t('Efficient Model-Based Reinforcement Learning through Optimistic Policy Search and Planning', '2020')\n",
            "\t('Coresets via Bilevel Optimization for Continual Learning and Streaming', '2020')\n",
            "\t('Contextual Games: Multi-Agent Learning with Side Information', '2020')\n",
            "\t('Meta-Learning Reliable Priors in the Function Space', '2021')\n",
            "\t('Near-Optimal Multi-Perturbation Experimental Design for Causal Structure Learning', '2021')\n",
            "\t('Misspecified Gaussian Process Bandit Optimization', '2021')\n",
            "\t('Information Directed Reward Learning for Reinforcement Learning', '2021')\n",
            "\t('Regret Bounds for Gaussian-Process Optimization in Large Domains', '2021')\n",
            "\t('Learning Graph Models for Retrosynthesis Prediction', '2021')\n",
            "\t('Hierarchical Skills for Efficient Exploration', '2021')\n",
            "\t('Learning Stable Deep Dynamics Models for Partially Observed or Delayed Dynamical Systems', '2021')\n",
            "\t('Risk-averse Heteroscedastic Bayesian Optimization', '2021')\n",
            "\t('DiBS: Differentiable Bayesian Structure Learning', '2021')\n",
            "\t('Multi-Scale Representation Learning on Proteins', '2021')\n",
            "\t('Robust Generalization despite Distribution Shift via Minimum Discriminating Information', '2021')\n",
            "\t('Distributional Gradient Matching for Learning Uncertain Neural Dynamics Models', '2021')\n",
            "Sergey Levine\n",
            "\t('Feature Construction for Inverse Reinforcement Learning', '2010')\n",
            "\t('Nonlinear Inverse Reinforcement Learning with Gaussian Processes', '2011')\n",
            "\t('Variational Policy Search via Trajectory Optimization', '2013')\n",
            "\t('Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics', '2014')\n",
            "\t('Backprop KF: Learning Discriminative Deterministic State Estimators', '2016')\n",
            "\t('Guided Policy Search via Approximate Mirror Descent', '2016')\n",
            "\t('Learning to Poke by Poking: Experiential Learning of Intuitive Physics', '2016')\n",
            "\t('Value Iteration Networks', '2016')\n",
            "\t('Unsupervised Learning for Physical Interaction through Video Prediction', '2016')\n",
            "\t('EX2: Exploration with Exemplar Models for Deep Reinforcement Learning', '2017')\n",
            "\t('Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning', '2017')\n",
            "\t('Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models', '2018')\n",
            "\t('Meta-Reinforcement Learning of Structured Exploration Strategies', '2018')\n",
            "\t('Visual Memory for Robust Path Following', '2018')\n",
            "\t(\"Where Do You Think You're Going?: Inferring Beliefs about Dynamics from Behavior\", '2018')\n",
            "\t('Visual Reinforcement Learning with Imagined Goals', '2018')\n",
            "\t('Probabilistic Model-Agnostic Meta-Learning', '2018')\n",
            "\t('Variational Inverse Control with Events: A General Framework for Data-Driven Reward Definition', '2018')\n",
            "\t('Data-Efficient Hierarchical Reinforcement Learning', '2018')\n",
            "\t('Compositional Plan Vectors', '2019')\n",
            "\t('Meta-Learning with Implicit Gradients', '2019')\n",
            "\t('Search on the Replay Buffer: Bridging Planning and Reinforcement Learning', '2019')\n",
            "\t('When to Trust Your Model: Model-Based Policy Optimization', '2019')\n",
            "\t('Causal Confusion in Imitation Learning', '2019')\n",
            "\t('MCP: Learning Composable Hierarchical Control with Multiplicative Compositional Policies', '2019')\n",
            "\t('Off-Policy Evaluation via Off-Policy Classification', '2019')\n",
            "\t('Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction', '2019')\n",
            "\t('Planning with Goal-Conditioned Policies', '2019')\n",
            "\t('Guided Meta-Policy Search', '2019')\n",
            "\t('Unsupervised Curricula for Visual Meta-Reinforcement Learning', '2019')\n",
            "\t('Wasserstein Dependency Measure for Representation Learning', '2019')\n",
            "\t('Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model', '2020')\n",
            "\t('Conservative Q-Learning for Offline Reinforcement Learning', '2020')\n",
            "\t('Gamma-Models: Generative Temporal Difference Learning for Infinite-Horizon Prediction', '2020')\n",
            "\t('Continual Learning of Control Primitives : Skill Discovery via Reset-Games', '2020')\n",
            "\t('Model Inversion Networks for Model-Based Optimization', '2020')\n",
            "\t('Gradient Surgery for Multi-Task Learning', '2020')\n",
            "\t('One Solution is Not All You Need: Few-Shot Extrapolation via Structured MaxEnt RL', '2020')\n",
            "\t('Emergent Complexity and Zero-shot Transfer via Unsupervised Environment Design', '2020')\n",
            "\t('MOPO: Model-based Offline Policy Optimization', '2020')\n",
            "\t('Rewriting History with Inverse RL: Hindsight Inference for Policy Improvement', '2020')\n",
            "\t('Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors', '2020')\n",
            "\t('DisCor: Corrective Feedback in Reinforcement Learning via Distribution Correction', '2020')\n",
            "\t('Bayesian Adaptation for Covariate Shift', '2021')\n",
            "\t('Offline Reinforcement Learning as One Big Sequence Modeling Problem', '2021')\n",
            "\t('Information is Power: Intrinsic Control via Information Capture', '2021')\n",
            "\t('Conservative Data Sharing for Multi-Task Offline Reinforcement Learning', '2021')\n",
            "\t('Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification', '2021')\n",
            "\t('Outcome-Driven Reinforcement Learning via Variational Inference', '2021')\n",
            "\t('Autonomous Reinforcement Learning via Subgoal Curricula', '2021')\n",
            "\t('Adaptive Risk Minimization: Learning to Adapt to Domain Shift', '2021')\n",
            "\t('Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability', '2021')\n",
            "\t('Which Mutual-Information Representation Learning Objectives are Sufficient for Control?', '2021')\n",
            "\t('Pragmatic Image Compression for Human-in-the-Loop Decision-Making', '2021')\n",
            "\t('Robust Predictable Control', '2021')\n",
            "\t('COMBO: Conservative Offline Model-Based Policy Optimization', '2021')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.hist(np.array(list(author_counts.values())), bins= 79)\n",
        "_ = plt.ylim(0, 4000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Fd6bYIdoAgww",
        "outputId": "da8d3777-7f3d-44ed-c645-5bc2b32e6169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most authors have published only one paper. therefore, we need to pick a small enough support threshold value (under 10)"
      ],
      "metadata": {
        "id": "eFzu8XEgA-qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "support_threshold = 10"
      ],
      "metadata": {
        "id": "Vkiv24wlAi4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# between passes, find frequent authors\n",
        "frequent_authors = []\n",
        "\n",
        "for author in author_counts:\n",
        "  if author_counts[author] >= support_threshold:\n",
        "    frequent_authors.append(author)\n",
        "\n",
        "\n",
        "print('number of frequent authors:', len(frequent_authors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2iipzQFBPa_",
        "outputId": "693676da-d48b-428e-a393-a9a1ed1f8cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of frequent authors: 570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pass 2: count only pairs when both authors are frequent\n",
        "pair_counts = {}\n",
        "\n",
        "with open('nips_authors_id.csv', 'r') as f:\n",
        "  reader = csv.reader(f, delimiter=',')\n",
        "  for row in reader:\n",
        "    for author_x, author_y in combinations(row[1:], 2):\n",
        "      if author_x in frequent_authors and author_y in frequent_authors:\n",
        "        # update pair counts dictionary\n",
        "        pair = frozenset({author_x, author_y})\n",
        "        if pair in pair_counts:\n",
        "          pair_counts[pair] += 1\n",
        "        else:\n",
        "          pair_counts[pair] = 1"
      ],
      "metadata": {
        "id": "W21OMvfqBsuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter out non-frequent pairs\n",
        "\n",
        "frequent_pairs = []\n",
        "\n",
        "# between passes, find frequent pairs\n",
        "for pair in pair_counts:\n",
        "  if pair_counts[pair] >= support_threshold:\n",
        "    frequent_pairs.append(pair)\n",
        "\n",
        "\n",
        "print('number of frequent author pairs:', len(frequent_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UTfN9PHCVIv",
        "outputId": "c501fa04-a64a-4a35-ff5e-78a0f2ac20d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of frequent author pairs: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of pairs of authors who have published at least 10 NIPS papers together"
      ],
      "metadata": {
        "id": "8hInVQv9mDxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for pair in list(map(lambda x: set(x), frequent_pairs)):\n",
        "  for auth in pair:\n",
        "    print(id_2_author[int(auth)], end='\\t')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_AQYegVD67d",
        "outputId": "f6129f36-528e-4a58-f621-f70583cbb0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alex Smola\tBernhard Schölkopf\t\n",
            "Ralf Herbrich\tThore Graepel\t\n",
            "Mehryar Mohri\tCorinna Cortes\t\n",
            "Alyson K. Fletcher\tSundeep Rangan\t\n",
            "Bo Zhang\tJun Zhu\t\n",
            "Masashi Sugiyama\tGang Niu\t\n",
            "Tianbao Yang\tRong Jin\t\n",
            "Pradeep K. Ravikumar\tInderjit S. Dhillon\t\n",
            "Praneeth Netrapalli\tPrateek Jain\t\n",
            "Tie-Yan Liu\tTao Qin\t\n",
            "Jiashi Feng\tShuicheng Yan\t\n",
            "Lorenzo Rosasco\tAlessandro Rudi\t\n",
            "Florent Krzakala\tLenka Zdeborová\t\n",
            "Remi Munos\tMichal Valko\t\n",
            "Han Liu\tZhaoran Wang\t\n",
            "Ricardo Henao\tLawrence Carin\t\n",
            "Jiajun Wu\tBill Freeman\t\n",
            "Jiajun Wu\tJosh Tenenbaum\t\n",
            "Josh Tenenbaum\tBill Freeman\t\n",
            "Chang Xu\tYunhe Wang\t\n",
            "David Silver\tHado P. van Hasselt\t\n",
            "Zhuoran Yang\tZhaoran Wang\t\n",
            "Mingsheng Long\tJianmin Wang\t\n",
            "Sergey Levine\tChelsea Finn\t\n",
            "Cho-Jui Hsieh\tHuan Zhang\t\n",
            "Stefano Ermon\tJiaming Song\t\n",
            "Alessandro Lazaric\tMatteo Pirotta\t\n",
            "Stefano Ermon\tYang Song\t\n",
            "Tamer Basar\tKaiqing Zhang\t\n",
            "Tianlong Chen\tZhangyang Wang\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing general multi-pass A-priori\n",
        "\n",
        "We can find bigger frequent itemsets by abstracting A-priori into two parts and repeatedly running them sequentially:\n",
        "\n",
        "```\n",
        "genCandidates(size=1) -> filter_candidates -> genCandidates(size=2) -> filter_candidates -> genCandidates(size=3) -> filter_candidates -> ...\n",
        "\n",
        "```\n",
        "```\n",
        "frequentSets(n-1), frequentSets(1) -> gencandidates -> CandidateSets(n)\n",
        "CandidateSets(n) -> filter_candidates(n) -> frequentSets(n)\n",
        "```"
      ],
      "metadata": {
        "id": "1WPeSP0FI_HC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_candidates(frequent_sets, frequent_items):\n",
        "  # frequent_sets -> list of frequent sets of size n-1\n",
        "  # frequent_items -> list of frequent items(singletons)\n",
        "  # candidates -> list of set of candidate items\n",
        "\n",
        "  n = len(frequent_sets[0])\n",
        "\n",
        "  # generate all possible sets by picking a frequent set (size: n-1) and a frequent item (size: 1)\n",
        "  candidates = map(lambda x:x[0]|x[1], product(frequent_items, frequent_sets))\n",
        "\n",
        "  # filter out all cases where we merge by an item already in the set (e.g. {x} | {x,y})\n",
        "  candidates = filter(lambda x: len(x) == n + 1, candidates)\n",
        "\n",
        "  return list(candidates)"
      ],
      "metadata": {
        "id": "nJw8Cg8CFKn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_candidates(candidates):\n",
        "  # candidates -> list of candidate sets of size n\n",
        "  # frequent_sets -> list of verified frequent sets\n",
        "\n",
        "  # what size itemset are we looking for\n",
        "  n = len(candidates[0])\n",
        "\n",
        "  candidateset = {frozenset(x) for x in candidates}\n",
        "\n",
        "  counts = {}\n",
        "\n",
        "  with open('nips_authors_id.csv', 'r') as f:\n",
        "    reader = csv.reader(f, delimiter=',')\n",
        "    for row in reader:\n",
        "      # for all possible combinations of n elements in each basket\n",
        "      for items in combinations(row[1:], n):\n",
        "        if set(items) in candidateset:\n",
        "          # update counts dictionary\n",
        "          frozen_items = frozenset(items)\n",
        "          if frozen_items in counts:\n",
        "            counts[frozen_items] += 1\n",
        "          else:\n",
        "            counts[frozen_items] = 1\n",
        "\n",
        "\n",
        "  # filter out items below support threshold\n",
        "  frequent_sets = filter(lambda x: counts[x] >= support_threshold, counts)\n",
        "  frequent_sets = list(map(lambda x: set(x), frequent_sets))\n",
        "\n",
        "\n",
        "\n",
        "  return frequent_sets, counts"
      ],
      "metadata": {
        "id": "tDFdzcSdK5Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lowering the threshold to find more frequent co-authors\n",
        "support_threshold = 5\n",
        "\n",
        "frequent_authors = []\n",
        "\n",
        "# find frequent authors\n",
        "for author in author_counts:\n",
        "  if author_counts[author] >= support_threshold:\n",
        "    frequent_authors.append(author)\n",
        "\n",
        "\n",
        "print('number of frequent authors:', len(frequent_authors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QIb127QeIkg",
        "outputId": "1a59892c-f9cf-49f5-9651-094d84016351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of frequent authors: 1786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# repeatedly run A-priori to capture all frequent itemsets\n",
        "\n",
        "frequent_items = list(map(lambda x: {x}, frequent_authors))\n",
        "\n",
        "# keep a list of all frequent itemsets\n",
        "frequent_sets = []\n",
        "# keep count of all candidate itemset counts (including the frequent ones)\n",
        "counts_dict = {}\n",
        "\n",
        "# update aggregates with size 1 itemsets\n",
        "frequent_sets.append(frequent_items)\n",
        "counts_dict.update({frozenset({x}):author_counts[x] for x in author_counts})\n",
        "\n",
        "\n",
        "k = 0\n",
        "# repeat until there exists a larger candidate\n",
        "while len(frequent_sets[k]) != 0:\n",
        "  # run both A-priori passes\n",
        "  candidates = gen_candidates(frequent_sets[k],frequent_items)\n",
        "  freq_sets, counts = filter_candidates(candidates)\n",
        "  \n",
        "  # update aggregates with size n itemsets\n",
        "  frequent_sets.append(freq_sets)\n",
        "  counts_dict.update(counts)\n",
        "  k += 1"
      ],
      "metadata": {
        "id": "FtbV6lryb76x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answering question 2\n",
        "\n",
        "Which groups of researchers have published several papers together?\n",
        "\n",
        "We will consider a support threshold of 5 papers (groups must have at least 5 papers together to be considered frequent)"
      ],
      "metadata": {
        "id": "79_-4NuthRYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('number of frequent pairs:', len(frequent_sets[1]))\n",
        "print('number of frequent triples:', len(frequent_sets[2]))\n",
        "print('number of frequent quadruples:', len(frequent_sets[3]))\n",
        "print('number of frequent quintuples:', len(frequent_sets[4]))\n",
        "print('number of frequent sextuples:', len(frequent_sets[5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II3DbX5_fA9T",
        "outputId": "33d1e348-d8d1-45ad-b52d-501fcbb9d808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of frequent pairs: 407\n",
            "number of frequent triples: 68\n",
            "number of frequent quadruples: 30\n",
            "number of frequent quintuples: 12\n",
            "number of frequent sextuples: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Groups of 3 authors who have at least 5 NIPS papers together\n",
        "for team in frequent_sets[3]:\n",
        "  for auth in map(lambda x:id_2_author[int(x)], team):\n",
        "    print(auth, end='  ')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ5w39JOpqkh",
        "outputId": "dded46e7-bffc-4b8e-fbe5-548cad3a8ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shinji Ito  Takuro Fukunaga  Daisuke Hatano  Hanna Sumita  \n",
            "Shinji Ito  Naonori Kakimura  Daisuke Hatano  Hanna Sumita  \n",
            "Shinji Ito  Daisuke Hatano  Ken-Ichi Kawarabayashi  Hanna Sumita  \n",
            "Shinji Ito  Takuro Fukunaga  Daisuke Hatano  Naonori Kakimura  \n",
            "Shinji Ito  Takuro Fukunaga  Daisuke Hatano  Ken-Ichi Kawarabayashi  \n",
            "Shinji Ito  Naonori Kakimura  Daisuke Hatano  Ken-Ichi Kawarabayashi  \n",
            "Shinji Ito  Takuro Fukunaga  Naonori Kakimura  Hanna Sumita  \n",
            "Shinji Ito  Takuro Fukunaga  Ken-Ichi Kawarabayashi  Hanna Sumita  \n",
            "Shinji Ito  Naonori Kakimura  Ken-Ichi Kawarabayashi  Hanna Sumita  \n",
            "Shinji Ito  Takuro Fukunaga  Naonori Kakimura  Ken-Ichi Kawarabayashi  \n",
            "Takuro Fukunaga  Naonori Kakimura  Daisuke Hatano  Hanna Sumita  \n",
            "Takuro Fukunaga  Daisuke Hatano  Ken-Ichi Kawarabayashi  Hanna Sumita  \n",
            "Naonori Kakimura  Daisuke Hatano  Ken-Ichi Kawarabayashi  Hanna Sumita  \n",
            "Takuro Fukunaga  Naonori Kakimura  Daisuke Hatano  Ken-Ichi Kawarabayashi  \n",
            "Takuro Fukunaga  Naonori Kakimura  Ken-Ichi Kawarabayashi  Hanna Sumita  \n",
            "Zhongwen Xu  Junhyuk Oh  Matteo Hessel  Hado P. van Hasselt  \n",
            "Zhongwen Xu  Junhyuk Oh  David Silver  Matteo Hessel  \n",
            "Zhongwen Xu  Junhyuk Oh  Matteo Hessel  Satinder Singh  \n",
            "Zhongwen Xu  David Silver  Matteo Hessel  Hado P. van Hasselt  \n",
            "Zhongwen Xu  Matteo Hessel  Hado P. van Hasselt  Satinder Singh  \n",
            "Zhongwen Xu  David Silver  Matteo Hessel  Satinder Singh  \n",
            "Junhyuk Oh  David Silver  Matteo Hessel  Hado P. van Hasselt  \n",
            "Junhyuk Oh  Matteo Hessel  Hado P. van Hasselt  Satinder Singh  \n",
            "Junhyuk Oh  David Silver  Matteo Hessel  Satinder Singh  \n",
            "David Silver  Matteo Hessel  Hado P. van Hasselt  Satinder Singh  \n",
            "Junhyuk Oh  David Silver  Zhongwen Xu  Hado P. van Hasselt  \n",
            "Junhyuk Oh  Zhongwen Xu  Hado P. van Hasselt  Satinder Singh  \n",
            "Junhyuk Oh  David Silver  Zhongwen Xu  Satinder Singh  \n",
            "David Silver  Zhongwen Xu  Hado P. van Hasselt  Satinder Singh  \n",
            "Junhyuk Oh  David Silver  Hado P. van Hasselt  Satinder Singh  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Groups of 5 authors who have at least 5 NIPS papers together\n",
        "for team in frequent_sets[4]:\n",
        "  for auth in map(lambda x:id_2_author[int(x)], team):\n",
        "    print(auth, end='  ')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTOko04sc0qA",
        "outputId": "28b35e14-19c5-42cb-b4d6-335e59a23791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shinji Ito  Takuro Fukunaga  Hanna Sumita  Naonori Kakimura  Daisuke Hatano  \n",
            "Shinji Ito  Takuro Fukunaga  Ken-Ichi Kawarabayashi  Hanna Sumita  Daisuke Hatano  \n",
            "Shinji Ito  Ken-Ichi Kawarabayashi  Hanna Sumita  Naonori Kakimura  Daisuke Hatano  \n",
            "Shinji Ito  Takuro Fukunaga  Ken-Ichi Kawarabayashi  Naonori Kakimura  Daisuke Hatano  \n",
            "Shinji Ito  Takuro Fukunaga  Hanna Sumita  Naonori Kakimura  Ken-Ichi Kawarabayashi  \n",
            "Takuro Fukunaga  Ken-Ichi Kawarabayashi  Hanna Sumita  Naonori Kakimura  Daisuke Hatano  \n",
            "Zhongwen Xu  Hado P. van Hasselt  Junhyuk Oh  David Silver  Matteo Hessel  \n",
            "Zhongwen Xu  Hado P. van Hasselt  Satinder Singh  Junhyuk Oh  Matteo Hessel  \n",
            "Zhongwen Xu  Satinder Singh  Junhyuk Oh  David Silver  Matteo Hessel  \n",
            "Zhongwen Xu  Hado P. van Hasselt  Satinder Singh  David Silver  Matteo Hessel  \n",
            "Hado P. van Hasselt  Satinder Singh  Junhyuk Oh  David Silver  Matteo Hessel  \n",
            "Zhongwen Xu  Satinder Singh  Junhyuk Oh  David Silver  Hado P. van Hasselt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Groups of 6 authors who have at least 5 NIPS papers in common\n",
        "for team in frequent_sets[5]:\n",
        "  for auth in map(lambda x:id_2_author[int(x)], team):\n",
        "    print(auth, end='  ')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcvBovlHdIWH",
        "outputId": "e2245add-8b16-4439-d89c-c4c3aa30d5be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shinji Ito  Takuro Fukunaga  Ken-Ichi Kawarabayashi  Hanna Sumita  Naonori Kakimura  Daisuke Hatano  \n",
            "Zhongwen Xu  Hado P. van Hasselt  Satinder Singh  Junhyuk Oh  David Silver  Matteo Hessel  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Association Mining\n",
        "\n",
        "## Generating association rules\n",
        "\n",
        "Association rules are frequent IF-THEN occurances of events together. For example if $\\{i_1,\\dots,i_n\\}$ is a frequent itemset, $\\{i_2,\\dots,i_n\\} \\to i_1$ is an association rule. But not all such rules are that interesting.\n",
        "\n",
        "For example, If we have 100 frequent pairs of items then there are 200 association rules of the form $[x \\to y]$. However, most of these rules don't give us actual information about relationships between items. Maybe the two items are independently frequent and therefore show up together many times or perhaps some items co-occur with many different items in different circumstances thus not giving us a useful IT-THEN relationship.\n",
        "\n",
        "There are several measures of \"goodness\" for association rules. Let us introduce one such measure called \"confidence\".\n",
        "\n",
        "### Confidence\n",
        "\n",
        "Confidence measures what fraction of times $\\{i_2,\\dots,i_n\\}$ co-occur with $\\{i_1\\}$. Namely, if $ I =\\{ i_2, \\dots, i_n \\}$, then,\n",
        "$$\n",
        "\\text{Confidence}(I \\to i_1) = \\frac{\\text{Support}(I \\cup \\{i_1\\})}{\\text{Support}(I)}\n",
        "$$\n",
        "\n",
        "Let's find association rules of the form:\n",
        "$$\n",
        "X \\to Y\n",
        "$$\n",
        "For frequent pairs (support threshold = 5)"
      ],
      "metadata": {
        "id": "evqUIvBmhl6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find associations\n",
        "# X -> Y   associations[(X,Y)] = conf(X->Y)\n",
        "associations = {}\n",
        "\n",
        "\n",
        "freq_pairs = frequent_sets[1]\n",
        "\n",
        "for pair in freq_pairs:\n",
        "  # {X,Y}\n",
        "  pair = list(pair)\n",
        "\n",
        "  # X -> Y\n",
        "  X = pair[0]\n",
        "  Y = pair[1]\n",
        "  associations[X,Y] = None\n",
        "\n",
        "  # Y -> X\n",
        "  X = pair[1]\n",
        "  Y = pair[0]\n",
        "  associations[X,Y] = None"
      ],
      "metadata": {
        "id": "xZ-2rEhTFnLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate confidence of associations\n",
        "for association in associations:\n",
        "  # I -> j\n",
        "  I = {association[0]}\n",
        "  j = {association[1]}\n",
        "  \n",
        "  associations[association] =  counts_dict[frozenset(I | j)] / counts_dict[frozenset(I)]"
      ],
      "metadata": {
        "id": "wYvyxTDacvqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Association confidence of pairs for support thereshold 5\n",
        "associations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rJkpTCrjqVt",
        "outputId": "c5faeffb-747a-4c78-ca18-9626ab28fc69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('1001356832', '1473784883'): 0.1935483870967742,\n",
              " ('1001356832', '3390784942'): 0.16129032258064516,\n",
              " ('1001356832', '4144433279'): 0.25806451612903225,\n",
              " ('1001356832', '748457644'): 0.22580645161290322,\n",
              " ('1001455660', '2355635187'): 0.8333333333333334,\n",
              " ('1004145066', '1271151121'): 0.8571428571428571,\n",
              " ('1007220190', '4097041451'): 0.25,\n",
              " ('1029041475', '1983995262'): 0.21428571428571427,\n",
              " ('1029041475', '212160062'): 0.5,\n",
              " ('1029041475', '2344999919'): 0.17857142857142858,\n",
              " ('1029041475', '2654352847'): 0.32142857142857145,\n",
              " ('1029041475', '428475226'): 0.21428571428571427,\n",
              " ('1029829025', '4017234740'): 0.25,\n",
              " ('1050619812', '406844425'): 0.4166666666666667,\n",
              " ('1054694307', '872811929'): 0.3888888888888889,\n",
              " ('1056844424', '1889764238'): 0.7142857142857143,\n",
              " ('1091790929', '2023891181'): 0.2777777777777778,\n",
              " ('1091790929', '2493318935'): 0.5,\n",
              " ('1111677806', '3253308491'): 0.4166666666666667,\n",
              " ('111482447', '584759982'): 0.7142857142857143,\n",
              " ('1118746000', '1514060377'): 0.45454545454545453,\n",
              " ('1118746000', '1802347277'): 0.45454545454545453,\n",
              " ('1118746000', '2433797681'): 0.45454545454545453,\n",
              " ('1118746000', '4028600581'): 0.45454545454545453,\n",
              " ('1118746000', '645710987'): 0.45454545454545453,\n",
              " ('112398026', '1391025731'): 0.2727272727272727,\n",
              " ('1124147890', '2278524667'): 0.3,\n",
              " ('1124147890', '3754036067'): 0.25,\n",
              " ('1124950233', '1277831649'): 0.16666666666666666,\n",
              " ('1124950233', '1290887240'): 0.35714285714285715,\n",
              " ('1124950233', '2959159250'): 0.16666666666666666,\n",
              " ('1161833345', '1748539345'): 0.7142857142857143,\n",
              " ('1169900393', '2161561469'): 0.21739130434782608,\n",
              " ('1170454528', '207310109'): 0.46153846153846156,\n",
              " ('1174651180', '2189852989'): 0.17647058823529413,\n",
              " ('1189121577', '1453106299'): 1.0,\n",
              " ('1197233505', '2653997740'): 0.5555555555555556,\n",
              " ('1197233505', '3701030057'): 0.8888888888888888,\n",
              " ('1205208901', '1215510114'): 0.08695652173913043,\n",
              " ('1205208901', '2439282353'): 0.10144927536231885,\n",
              " ('1205208901', '4267504215'): 0.08695652173913043,\n",
              " ('120931195', '3841123463'): 0.25,\n",
              " ('1215510114', '1205208901'): 0.15,\n",
              " ('1232791679', '2512988594'): 0.8571428571428571,\n",
              " ('1232791679', '470696179'): 1.0,\n",
              " ('1245326756', '4160523084'): 0.6363636363636364,\n",
              " ('1245517116', '1608947994'): 0.5555555555555556,\n",
              " ('1245517116', '247595010'): 0.7777777777777778,\n",
              " ('1245517116', '804407327'): 0.5555555555555556,\n",
              " ('125624950', '470696179'): 0.4,\n",
              " ('1262807525', '2029349294'): 0.3333333333333333,\n",
              " ('1271151121', '1004145066'): 0.5,\n",
              " ('1271151121', '682380085'): 0.5,\n",
              " ('1277831649', '1124950233'): 0.6363636363636364,\n",
              " ('1277831649', '1290887240'): 0.8181818181818182,\n",
              " ('1277831649', '497251668'): 0.6363636363636364,\n",
              " ('1278880239', '296623680'): 0.8421052631578947,\n",
              " ('1278880239', '3884244346'): 0.2631578947368421,\n",
              " ('127995826', '2766558226'): 1.0,\n",
              " ('128836949', '3261192163'): 0.7142857142857143,\n",
              " ('1290887240', '1124950233'): 0.8823529411764706,\n",
              " ('1290887240', '1277831649'): 0.5294117647058824,\n",
              " ('1290887240', '497251668'): 0.35294117647058826,\n",
              " ('1298253901', '2834956399'): 0.125,\n",
              " ('1298253901', '3474694173'): 0.10416666666666667,\n",
              " ('1298253901', '3701030057'): 0.1875,\n",
              " ('1301130341', '350371951'): 0.5,\n",
              " ('1305839300', '2434026695'): 1.0,\n",
              " ('1307276742', '556240111'): 0.8461538461538461,\n",
              " ('1326939511', '2253729304'): 0.15151515151515152,\n",
              " ('1326939511', '819479719'): 0.15151515151515152,\n",
              " ('13323837', '3215085756'): 0.3,\n",
              " ('1335984637', '2227729410'): 0.4666666666666667,\n",
              " ('1342359609', '2937477401'): 0.6,\n",
              " ('1344382608', '2480497339'): 1.0,\n",
              " ('1345978760', '2052357883'): 0.0847457627118644,\n",
              " ('1345978760', '2944703640'): 0.0847457627118644,\n",
              " ('1345978760', '4282252781'): 0.0847457627118644,\n",
              " ('1345978760', '872811929'): 0.0847457627118644,\n",
              " ('1348681189', '633084345'): 0.2727272727272727,\n",
              " ('1356029419', '207310109'): 0.16666666666666666,\n",
              " ('1356029419', '3436575269'): 0.16666666666666666,\n",
              " ('1356029419', '3525728115'): 0.36666666666666664,\n",
              " ('135626747', '471388580'): 0.12195121951219512,\n",
              " ('1360481343', '1760141407'): 1.0,\n",
              " ('1366369787', '1553134296'): 0.2777777777777778,\n",
              " ('136702941', '3417893845'): 1.0,\n",
              " ('1369219426', '576264751'): 0.875,\n",
              " ('1370681478', '1619581288'): 1.0,\n",
              " ('1391025731', '112398026'): 0.8571428571428571,\n",
              " ('139882176', '1463160344'): 0.3235294117647059,\n",
              " ('139882176', '2288948635'): 0.14705882352941177,\n",
              " ('139882176', '3548737114'): 0.14705882352941177,\n",
              " ('139882176', '86810146'): 0.17647058823529413,\n",
              " ('1400438326', '2653556677'): 0.5,\n",
              " ('1407649050', '4032439473'): 0.5,\n",
              " ('1407649050', '4207443520'): 0.6,\n",
              " ('141266136', '2319707579'): 0.2777777777777778,\n",
              " ('141266136', '665645192'): 0.3333333333333333,\n",
              " ('1414649122', '2299019096'): 0.46153846153846156,\n",
              " ('1414649122', '682380085'): 0.6153846153846154,\n",
              " ('1432666603', '1747365026'): 0.7777777777777778,\n",
              " ('1434510306', '312414676'): 0.38461538461538464,\n",
              " ('1434510306', '3532824385'): 0.38461538461538464,\n",
              " ('1434510306', '3536446306'): 0.38461538461538464,\n",
              " ('1446694012', '2283932875'): 0.2777777777777778,\n",
              " ('1446694012', '4244144558'): 0.3333333333333333,\n",
              " ('1453106299', '1189121577'): 0.1875,\n",
              " ('1453106299', '3439053735'): 0.15625,\n",
              " ('1453106299', '3686824712'): 0.21875,\n",
              " ('1453106299', '3993255746'): 0.15625,\n",
              " ('1453106299', '880638866'): 0.1875,\n",
              " ('1457781808', '4118445004'): 0.2727272727272727,\n",
              " ('1457781808', '4261081585'): 0.22727272727272727,\n",
              " ('1460084329', '2553919588'): 1.0,\n",
              " ('1463160344', '139882176'): 0.2894736842105263,\n",
              " ('1463160344', '4229676404'): 0.6842105263157895,\n",
              " ('1463160344', '791375045'): 0.15789473684210525,\n",
              " ('1473784883', '1001356832'): 0.75,\n",
              " ('1483274840', '3332548798'): 0.15151515151515152,\n",
              " ('1483274840', '3971736619'): 0.24242424242424243,\n",
              " ('1483934105', '2125009592'): 0.625,\n",
              " ('1484653162', '1676867504'): 0.5555555555555556,\n",
              " ('1484653162', '3337000328'): 0.5555555555555556,\n",
              " ('1484653162', '3811033060'): 0.5555555555555556,\n",
              " ('1514060377', '1118746000'): 1.0,\n",
              " ('1514060377', '1802347277'): 1.0,\n",
              " ('1514060377', '2433797681'): 1.0,\n",
              " ('1514060377', '4028600581'): 1.0,\n",
              " ('1514060377', '645710987'): 1.0,\n",
              " ('152568301', '2590033134'): 1.0,\n",
              " ('1530308769', '3243230598'): 0.2631578947368421,\n",
              " ('1530944376', '3381293977'): 0.29411764705882354,\n",
              " ('1531433927', '51129094'): 0.8,\n",
              " ('1553134296', '1366369787'): 0.5,\n",
              " ('1578691114', '3094136786'): 0.25,\n",
              " ('1588560979', '2891613691'): 0.13043478260869565,\n",
              " ('1608947994', '1245517116'): 0.22727272727272727,\n",
              " ('1608947994', '247595010'): 0.2727272727272727,\n",
              " ('1608947994', '804407327'): 0.22727272727272727,\n",
              " ('1614317667', '2614846647'): 0.3,\n",
              " ('1615202689', '325490035'): 0.7142857142857143,\n",
              " ('1619581288', '1370681478'): 1.0,\n",
              " ('1624151051', '3772333781'): 0.3,\n",
              " ('1625938030', '2909396256'): 0.3181818181818182,\n",
              " ('1626978279', '964183707'): 1.0,\n",
              " ('1638242286', '2654352847'): 0.7142857142857143,\n",
              " ('1647470574', '2025732912'): 0.8333333333333334,\n",
              " ('1663507115', '3413046455'): 1.0,\n",
              " ('1676867504', '1484653162'): 1.0,\n",
              " ('1678991087', '2864203221'): 0.5555555555555556,\n",
              " ('1683733387', '2979289652'): 0.22727272727272727,\n",
              " ('1694623627', '2684856415'): 0.6666666666666666,\n",
              " ('1694623627', '4147961697'): 0.6666666666666666,\n",
              " ('1695285895', '572884180'): 0.23809523809523808,\n",
              " ('1699152513', '3238250772'): 0.2631578947368421,\n",
              " ('1699152513', '614867846'): 0.2631578947368421,\n",
              " ('1705842678', '852235790'): 0.7777777777777778,\n",
              " ('1719636451', '2241342514'): 0.4166666666666667,\n",
              " ('172470197', '542800332'): 0.625,\n",
              " ('1737377058', '3186714689'): 1.0,\n",
              " ('1747365026', '1432666603'): 1.0,\n",
              " ('1748539345', '1161833345'): 0.5,\n",
              " ('1749939371', '2392718975'): 0.8571428571428571,\n",
              " ('1754969824', '2336544809'): 0.3333333333333333,\n",
              " ('1760141407', '1360481343'): 0.4444444444444444,\n",
              " ('1760141407', '3412220740'): 0.3333333333333333,\n",
              " ('1765954746', '3520507611'): 1.0,\n",
              " ('1784105260', '3375657602'): 0.625,\n",
              " ('1786313808', '576264751'): 0.5,\n",
              " ('1787515316', '3466396625'): 0.2608695652173913,\n",
              " ('1802347277', '1118746000'): 1.0,\n",
              " ('1802347277', '1514060377'): 1.0,\n",
              " ('1802347277', '2433797681'): 1.0,\n",
              " ('1802347277', '4028600581'): 1.0,\n",
              " ('1802347277', '645710987'): 1.0,\n",
              " ('1840726313', '1844310398'): 0.5555555555555556,\n",
              " ('1840726313', '2360451987'): 0.5555555555555556,\n",
              " ('1844310398', '1840726313'): 0.625,\n",
              " ('188875566', '2241342514'): 0.10869565217391304,\n",
              " ('188875566', '2577993510'): 0.15217391304347827,\n",
              " ('188875566', '2580509263'): 0.17391304347826086,\n",
              " ('188875566', '2795143546'): 0.13043478260869565,\n",
              " ('188875566', '3170789650'): 0.13043478260869565,\n",
              " ('188875566', '3253308491'): 0.10869565217391304,\n",
              " ('188875566', '60608325'): 0.10869565217391304,\n",
              " ('188875566', '944216118'): 0.13043478260869565,\n",
              " ('1889432521', '3375657602'): 1.0,\n",
              " ('1889764238', '1056844424'): 0.22727272727272727,\n",
              " ('1920970642', '2443725770'): 0.4,\n",
              " ('1920970642', '2480497339'): 0.2,\n",
              " ('1943679809', '2780653586'): 0.7777777777777778,\n",
              " ('1950083015', '4066690169'): 0.35714285714285715,\n",
              " ('1982404484', '2164286975'): 0.36363636363636365,\n",
              " ('1982404484', '3340617112'): 0.22727272727272727,\n",
              " ('1983995262', '1029041475'): 0.8571428571428571,\n",
              " ('2005691425', '3417893845'): 0.7142857142857143,\n",
              " ('2009191947', '579147290'): 0.375,\n",
              " ('2016878527', '2253152241'): 0.5555555555555556,\n",
              " ('2016878527', '3375657602'): 0.7777777777777778,\n",
              " ('2016878527', '4124092616'): 0.5555555555555556,\n",
              " ('2019495605', '3027306743'): 0.8333333333333334,\n",
              " ('2023891181', '1091790929'): 0.625,\n",
              " ('2025732912', '1647470574'): 1.0,\n",
              " ('202626340', '2957281062'): 1.0,\n",
              " ('2029349294', '1262807525'): 0.11904761904761904,\n",
              " ('2029349294', '261202844'): 0.16666666666666666,\n",
              " ('2029349294', '894788450'): 0.2619047619047619,\n",
              " ('2037654457', '3685069970'): 0.45454545454545453,\n",
              " ('2048560962', '4066690169'): 0.8571428571428571,\n",
              " ('2050433645', '3375657602'): 1.0,\n",
              " ('2052357883', '1345978760'): 0.8333333333333334,\n",
              " ('2052357883', '3701030057'): 0.8333333333333334,\n",
              " ('207310109', '1170454528'): 0.2608695652173913,\n",
              " ('207310109', '1356029419'): 0.21739130434782608,\n",
              " ('2073669856', '3348014232'): 0.16666666666666666,\n",
              " ('2073669856', '4046848336'): 0.16666666666666666,\n",
              " ('2074836467', '2542911636'): 0.625,\n",
              " ('2074836467', '3754036067'): 0.625,\n",
              " ('2102425120', '2669770596'): 1.0,\n",
              " ('2105188584', '2319707579'): 1.0,\n",
              " ('2108554754', '4003009412'): 0.7142857142857143,\n",
              " ('212160062', '1029041475'): 0.4117647058823529,\n",
              " ('212160062', '2344999919'): 0.20588235294117646,\n",
              " ('212160062', '2493318935'): 0.14705882352941177,\n",
              " ('212160062', '2654352847'): 0.14705882352941177,\n",
              " ('2125009592', '1483934105'): 0.3125,\n",
              " ('2140312706', '3413046455'): 0.75,\n",
              " ('214150511', '4285944361'): 0.5,\n",
              " ('2144575575', '3525728115'): 0.875,\n",
              " ('2159519621', '584759982'): 1.0,\n",
              " ('2161561469', '1169900393'): 0.625,\n",
              " ('216234302', '2822076804'): 0.3333333333333333,\n",
              " ('2162970570', '3828331305'): 0.2,\n",
              " ('2164286975', '1982404484'): 0.8,\n",
              " ('2189852989', '1174651180'): 0.2857142857142857,\n",
              " ('2189852989', '3786443633'): 0.23809523809523808,\n",
              " ('2196659065', '247595010'): 0.6363636363636364,\n",
              " ('2196659065', '397746936'): 0.45454545454545453,\n",
              " ('2196659065', '804407327'): 0.8181818181818182,\n",
              " ('2209025073', '3186714689'): 1.0,\n",
              " ('2209025073', '3348014232'): 0.7142857142857143,\n",
              " ('2209025073', '3524859265'): 0.7142857142857143,\n",
              " ('2209025073', '4014848395'): 1.0,\n",
              " ('2209025073', '752036747'): 0.7142857142857143,\n",
              " ('2218467691', '264396596'): 0.625,\n",
              " ('2227729410', '1335984637'): 0.875,\n",
              " ('2241342514', '1719636451'): 0.1388888888888889,\n",
              " ('2241342514', '188875566'): 0.1388888888888889,\n",
              " ('2241342514', '2298291953'): 0.19444444444444445,\n",
              " ('2241342514', '3253308491'): 0.1388888888888889,\n",
              " ('2241342514', '576264751'): 0.2777777777777778,\n",
              " ('2253152241', '2016878527'): 0.35714285714285715,\n",
              " ('2253152241', '3375657602'): 0.9285714285714286,\n",
              " ('2253152241', '4124092616'): 0.5,\n",
              " ('2253729304', '1326939511'): 0.35714285714285715,\n",
              " ('2270472327', '789170565'): 0.5,\n",
              " ('2277587473', '4272876618'): 1.0,\n",
              " ('2277587473', '53147213'): 1.2,\n",
              " ('2278524667', '1124147890'): 0.21428571428571427,\n",
              " ('2281098805', '3375657602'): 1.0,\n",
              " ('2283932875', '1446694012'): 0.5,\n",
              " ('2288948635', '139882176'): 0.3333333333333333,\n",
              " ('2288948635', '2725910881'): 0.4666666666666667,\n",
              " ('2298291953', '2241342514'): 0.4117647058823529,\n",
              " ('2299019096', '1414649122'): 0.2857142857142857,\n",
              " ('2299019096', '2439282353'): 0.2857142857142857,\n",
              " ('2299019096', '971549563'): 0.47619047619047616,\n",
              " ('2319707579', '141266136'): 0.1111111111111111,\n",
              " ('2319707579', '2105188584'): 0.1111111111111111,\n",
              " ('2319707579', '2553143892'): 0.35555555555555557,\n",
              " ('2319707579', '4192645038'): 0.1111111111111111,\n",
              " ('2336544809', '1754969824'): 0.7142857142857143,\n",
              " ('2340793958', '3051827901'): 0.7142857142857143,\n",
              " ('2344999919', '1029041475'): 0.625,\n",
              " ('2344999919', '212160062'): 0.875,\n",
              " ('2355635187', '1001455660'): 0.45454545454545453,\n",
              " ('2355635187', '4261650261'): 0.5454545454545454,\n",
              " ('2355635187', '819479719'): 0.6363636363636364,\n",
              " ('2360451987', '1840726313'): 0.22727272727272727,\n",
              " ('2360451987', '39452777'): 0.5454545454545454,\n",
              " ('236129479', '626984693'): 1.0,\n",
              " ('2370165173', '3477623270'): 1.0,\n",
              " ('2378559658', '2780653586'): 0.5555555555555556,\n",
              " ('2378559658', '3417893845'): 0.6666666666666666,\n",
              " ('2389259247', '447265668'): 0.875,\n",
              " ('2392718975', '1749939371'): 0.375,\n",
              " ('2401608705', '3436671530'): 0.13513513513513514,\n",
              " ('2407582555', '297138598'): 0.23809523809523808,\n",
              " ('2409754340', '3513528495'): 0.8888888888888888,\n",
              " ('2417453396', '3578772690'): 1.0,\n",
              " ('2422423164', '3588221934'): 0.8333333333333334,\n",
              " ('2433797681', '1118746000'): 1.0,\n",
              " ('2433797681', '1514060377'): 1.0,\n",
              " ('2433797681', '1802347277'): 1.0,\n",
              " ('2433797681', '4028600581'): 1.0,\n",
              " ('2433797681', '645710987'): 1.0,\n",
              " ('2434026695', '1305839300'): 1.0,\n",
              " ('2439282353', '1205208901'): 0.1044776119402985,\n",
              " ('2439282353', '2299019096'): 0.08955223880597014,\n",
              " ('2439282353', '3879150379'): 0.07462686567164178,\n",
              " ('2443725770', '1920970642'): 0.7142857142857143,\n",
              " ('2443725770', '2480497339'): 0.35714285714285715,\n",
              " ('2449357786', '3934986721'): 0.5,\n",
              " ('2468856369', '3127234703'): 1.0,\n",
              " ('247595010', '1245517116'): 0.4375,\n",
              " ('247595010', '1608947994'): 0.375,\n",
              " ('247595010', '2196659065'): 0.4375,\n",
              " ('247595010', '804407327'): 0.8125,\n",
              " ('2480497339', '1344382608'): 0.35714285714285715,\n",
              " ('2480497339', '1920970642'): 0.35714285714285715,\n",
              " ('2480497339', '2443725770'): 0.35714285714285715,\n",
              " ('2493318935', '1091790929'): 0.5,\n",
              " ('2493318935', '212160062'): 0.2777777777777778,\n",
              " ('2499359404', '3849532435'): 0.4166666666666667,\n",
              " ('2501129165', '3293355148'): 0.7142857142857143,\n",
              " ('2507645664', '3849532435'): 0.46153846153846156,\n",
              " ('2507645664', '819217306'): 0.38461538461538464,\n",
              " ('2512988594', '1232791679'): 0.2222222222222222,\n",
              " ('2512988594', '3931865863'): 0.18518518518518517,\n",
              " ('2512988594', '4220744926'): 0.25925925925925924,\n",
              " ('2512988594', '470696179'): 0.9259259259259259,\n",
              " ('2536764768', '800578314'): 0.8333333333333334,\n",
              " ('2542659056', '4066690169'): 1.0,\n",
              " ('2542783', '3900436160'): 0.24,\n",
              " ('2542911636', '2074836467'): 0.17857142857142858,\n",
              " ('2542911636', '3754036067'): 0.21428571428571427,\n",
              " ('2548984784', '939467845'): 0.8333333333333334,\n",
              " ('2553143892', '2319707579'): 1.0,\n",
              " ('2553919588', '1460084329'): 1.0,\n",
              " ('2555193367', '3685069970'): 1.0,\n",
              " ('2575668150', '512356224'): 0.7777777777777778,\n",
              " ('2577993510', '188875566'): 0.7777777777777778,\n",
              " ('2580014233', '4147728743'): 0.5,\n",
              " ('2580509263', '188875566'): 0.2857142857142857,\n",
              " ('2580509263', '3170789650'): 0.2857142857142857,\n",
              " ('2580509263', '964183707'): 0.25,\n",
              " ('2590033134', '152568301'): 0.16216216216216217,\n",
              " ('2590033134', '3112452262'): 0.21621621621621623,\n",
              " ('2590033134', '4096709471'): 0.13513513513513514,\n",
              " ('2590033134', '536067059'): 0.21621621621621623,\n",
              " ('261202844', '2029349294'): 0.875,\n",
              " ('2614846647', '1614317667'): 0.23076923076923078,\n",
              " ('264396596', '2218467691'): 0.5,\n",
              " ('264396596', '3635476228'): 0.6,\n",
              " ('2653556677', '1400438326'): 0.35714285714285715,\n",
              " ('2653997740', '1197233505'): 0.20833333333333334,\n",
              " ('2653997740', '3701030057'): 0.625,\n",
              " ('2653997740', '712864023'): 0.2916666666666667,\n",
              " ('2654352847', '1029041475'): 0.28125,\n",
              " ('2654352847', '1638242286'): 0.3125,\n",
              " ('2654352847', '212160062'): 0.15625,\n",
              " ('2654352847', '269711433'): 0.1875,\n",
              " ('2654352847', '616314303'): 0.15625,\n",
              " ('2660569300', '2911915105'): 0.7142857142857143,\n",
              " ('2669770596', '2102425120'): 0.17857142857142858,\n",
              " ('2669770596', '2821889156'): 0.25,\n",
              " ('2669770596', '2965382144'): 0.17857142857142858,\n",
              " ('2678532305', '282813831'): 0.3181818181818182,\n",
              " ('2678532305', '3253308491'): 0.4090909090909091,\n",
              " ('2678532305', '576264751'): 0.22727272727272727,\n",
              " ('2684856415', '1694623627'): 1.0,\n",
              " ('2684856415', '4147961697'): 1.0,\n",
              " ('269711433', '2654352847'): 0.8571428571428571,\n",
              " ('269711433', '616314303'): 0.7142857142857143,\n",
              " ('2701906263', '3375657602'): 0.5,\n",
              " ('2725910881', '2288948635'): 0.3181818181818182,\n",
              " ('27402555', '2951255392'): 0.5454545454545454,\n",
              " ('2766558226', '127995826'): 0.5,\n",
              " ('2780653586', '1943679809'): 0.875,\n",
              " ('2780653586', '2378559658'): 0.625,\n",
              " ('278301913', '3694254632'): 0.4117647058823529,\n",
              " ('2795143546', '188875566'): 0.8571428571428571,\n",
              " ('2801340362', '3825026050'): 0.38461538461538464,\n",
              " ('2806264397', '862747054'): 0.23809523809523808,\n",
              " ('2816779129', '3417893845'): 0.9285714285714286,\n",
              " ('2821889156', '2669770596'): 0.7777777777777778,\n",
              " ('2821889156', '3462764509'): 0.5555555555555556,\n",
              " ('2822076804', '216234302'): 0.7142857142857143,\n",
              " ('282813831', '2678532305'): 0.7777777777777778,\n",
              " ('2834131571', '470696179'): 0.8571428571428571,\n",
              " ('2834956399', '1298253901'): 1.0,\n",
              " ('2858857601', '944216118'): 0.625,\n",
              " ('2864203221', '1678991087'): 0.5555555555555556,\n",
              " ('2885783340', '4244543344'): 0.8333333333333334,\n",
              " ('2891613691', '1588560979'): 0.4,\n",
              " ('2896023870', '3286309234'): 0.3125,\n",
              " ('2909396256', '1625938030'): 1.0,\n",
              " ('2911915105', '2660569300'): 0.4166666666666667,\n",
              " ('2920099749', '3504495874'): 1.0,\n",
              " ('2937477401', '1342359609'): 0.2608695652173913,\n",
              " ('2938586062', '3525728115'): 0.875,\n",
              " ('2944703640', '1345978760'): 0.22727272727272727,\n",
              " ('2944703640', '872811929'): 0.36363636363636365,\n",
              " ('2951255392', '27402555'): 0.23076923076923078,\n",
              " ('2951255392', '295895649'): 0.19230769230769232,\n",
              " ('2953404574', '3842023916'): 0.6470588235294118,\n",
              " ('2953404574', '819479719'): 0.9411764705882353,\n",
              " ('2957281062', '202626340'): 1.0,\n",
              " ('295895649', '2951255392'): 1.0,\n",
              " ('2959159250', '1124950233'): 0.875,\n",
              " ('2965382144', '2669770596'): 1.0,\n",
              " ('296623680', '1278880239'): 0.9411764705882353,\n",
              " ('296623680', '3884244346'): 0.29411764705882354,\n",
              " ('2968640146', '682380085'): 0.8333333333333334,\n",
              " ('297138598', '2407582555'): 0.5,\n",
              " ('2971867906', '660199781'): 0.42857142857142855,\n",
              " ('2977262011', '3804260007'): 0.6666666666666666,\n",
              " ('2979289652', '1683733387'): 1.0,\n",
              " ('300276821', '3477063606'): 0.1267605633802817,\n",
              " ('300276821', '3654121371'): 0.07042253521126761,\n",
              " ('300276821', '507167216'): 0.09859154929577464,\n",
              " ('300276821', '652971096'): 0.09859154929577464,\n",
              " ('3012790832', '626984693'): 1.0,\n",
              " ('3014861976', '3386978590'): 0.2222222222222222,\n",
              " ('3014861976', '3892126620'): 0.2222222222222222,\n",
              " ('3027306743', '2019495605'): 0.16129032258064516,\n",
              " ('3027306743', '63454557'): 0.16129032258064516,\n",
              " ('3028355864', '325490035'): 0.625,\n",
              " ('304107480', '964183707'): 0.2777777777777778,\n",
              " ('3051827901', '2340793958'): 1.0,\n",
              " ('3064964030', '369741937'): 0.8333333333333334,\n",
              " ('3064964030', '4097041451'): 1.0,\n",
              " ('3094136786', '1578691114'): 0.3125,\n",
              " ('3112452262', '2590033134'): 0.8888888888888888,\n",
              " ('312414676', '1434510306'): 0.5,\n",
              " ('3127234703', '2468856369'): 0.23809523809523808,\n",
              " ('3148062437', '920692749'): 0.24,\n",
              " ('3151851971', '61367588'): 0.8888888888888888,\n",
              " ('3170789650', '188875566'): 0.5,\n",
              " ('3170789650', '2580509263'): 0.6666666666666666,\n",
              " ('3177297155', '3268622872'): 0.7272727272727273,\n",
              " ('3186714689', '1737377058'): 0.2608695652173913,\n",
              " ('3186714689', '2209025073'): 0.30434782608695654,\n",
              " ('3186714689', '3348014232'): 0.30434782608695654,\n",
              " ('3186714689', '3524859265'): 0.21739130434782608,\n",
              " ('3186714689', '4014848395'): 0.43478260869565216,\n",
              " ('3186714689', '4085136918'): 0.21739130434782608,\n",
              " ('3186714689', '752036747'): 0.30434782608695654,\n",
              " ('3198137693', '401810495'): 0.3888888888888889,\n",
              " ('3201311000', '3879150379'): 0.625,\n",
              " ('3214201835', '3518637264'): 0.15625,\n",
              " ('3214201835', '4267504215'): 0.1875,\n",
              " ('3215085756', '13323837'): 0.5454545454545454,\n",
              " ('3219504657', '3495646179'): 1.0,\n",
              " ('3238250772', '1699152513'): 0.5555555555555556,\n",
              " ('3243230598', '1530308769'): 0.8333333333333334,\n",
              " ('3245669569', '3417893845'): 1.0,\n",
              " ('3246355936', '971549563'): 1.0,\n",
              " ('3250827323', '3785285448'): 1.0,\n",
              " ('3252324070', '3432491517'): 0.5,\n",
              " ('3253308491', '1111677806'): 0.15151515151515152,\n",
              " ('3253308491', '188875566'): 0.15151515151515152,\n",
              " ('3253308491', '2241342514'): 0.15151515151515152,\n",
              " ('3253308491', '2678532305'): 0.2727272727272727,\n",
              " ('3253308491', '576264751'): 0.24242424242424243,\n",
              " ('325490035', '1615202689'): 0.35714285714285715,\n",
              " ('325490035', '3028355864'): 0.35714285714285715,\n",
              " ('325490035', '3442002946'): 0.35714285714285715,\n",
              " ('3257075704', '70519573'): 0.7,\n",
              " ('3261192163', '128836949'): 0.7142857142857143,\n",
              " ('3268622872', '3177297155'): 0.38095238095238093,\n",
              " ('3279006093', '615028091'): 0.3125,\n",
              " ('3285887257', '468320348'): 0.42857142857142855,\n",
              " ('3286309234', '2896023870'): 1.0,\n",
              " ('3293355148', '2501129165'): 0.5,\n",
              " ('332587789', '3701030057'): 0.8888888888888888,\n",
              " ('3326952743', '4260611607'): 0.5555555555555556,\n",
              " ('3332548798', '1483274840'): 0.8333333333333334,\n",
              " ('3337000328', '1484653162'): 1.0,\n",
              " ('3337000328', '3811033060'): 1.0,\n",
              " ('3340617112', '1982404484'): 0.625,\n",
              " ('3348014232', '2073669856'): 0.14285714285714285,\n",
              " ('3348014232', '2209025073'): 0.14285714285714285,\n",
              " ('3348014232', '3186714689'): 0.2,\n",
              " ('3348014232', '3524859265'): 0.22857142857142856,\n",
              " ('3348014232', '3922099509'): 0.17142857142857143,\n",
              " ('3348014232', '4014848395'): 0.17142857142857143,\n",
              " ('3348014232', '752036747'): 0.14285714285714285,\n",
              " ('3375657602', '1784105260'): 0.08771929824561403,\n",
              " ('3375657602', '1889432521'): 0.10526315789473684,\n",
              " ('3375657602', '2016878527'): 0.12280701754385964,\n",
              " ('3375657602', '2050433645'): 0.10526315789473684,\n",
              " ('3375657602', '2253152241'): 0.22807017543859648,\n",
              " ('3375657602', '2281098805'): 0.08771929824561403,\n",
              " ('3375657602', '2701906263'): 0.08771929824561403,\n",
              " ('3375657602', '3378743324'): 0.08771929824561403,\n",
              " ('3375657602', '3423621196'): 0.15789473684210525,\n",
              " ('3375657602', '4124092616'): 0.15789473684210525,\n",
              " ('3378743324', '3375657602'): 0.8333333333333334,\n",
              " ('3378743324', '3423621196'): 0.8333333333333334,\n",
              " ('3381293977', '1530944376'): 1.0,\n",
              " ('3386749996', '4097041451'): 1.0,\n",
              " ('3386978590', '3014861976'): 0.75,\n",
              " ('3390784942', '1001356832'): 1.0,\n",
              " ('3408529014', '4241672560'): 0.4166666666666667,\n",
              " ('3408529014', '434709649'): 0.4166666666666667,\n",
              " ('3412220740', '1760141407'): 1.0,\n",
              " ('3413046455', '1663507115'): 0.09090909090909091,\n",
              " ('3413046455', '2140312706'): 0.10909090909090909,\n",
              " ('3413046455', '427015018'): 0.10909090909090909,\n",
              " ('3417893845', '136702941'): 0.1111111111111111,\n",
              " ('3417893845', '2005691425'): 0.1111111111111111,\n",
              " ('3417893845', '2378559658'): 0.13333333333333333,\n",
              " ('3417893845', '2816779129'): 0.28888888888888886,\n",
              " ('3417893845', '3245669569'): 0.13333333333333333,\n",
              " ('3417893845', '946584363'): 0.26666666666666666,\n",
              " ('3423621196', '3375657602'): 0.8181818181818182,\n",
              " ('3423621196', '3378743324'): 0.45454545454545453,\n",
              " ('3432491517', '3252324070'): 0.5555555555555556,\n",
              " ('3436575269', '1356029419'): 0.4166666666666667,\n",
              " ('3436671530', '2401608705'): 0.7142857142857143,\n",
              " ('3439053735', '1453106299'): 1.0,\n",
              " ('3442002946', '325490035'): 1.0,\n",
              " ('3455627795', '3685069970'): 0.4,\n",
              " ('3457012981', '4096709471'): 1.0,\n",
              " ('3462764509', '2821889156'): 1.0,\n",
              " ('3463828400', '4071730666'): 0.3333333333333333,\n",
              " ('3463828400', '4097041451'): 0.7333333333333333,\n",
              " ('3466396625', '1787515316'): 0.75,\n",
              " ('3474694173', '1298253901'): 1.0,\n",
              " ('3476740986', '3845519378'): 0.6,\n",
              " ('3477063606', '300276821'): 0.75,\n",
              " ('3477623270', '2370165173'): 1.0,\n",
              " ('3495646179', '3219504657'): 0.35714285714285715,\n",
              " ('3497747092', '897182880'): 0.5555555555555556,\n",
              " ('3503341808', '3649059762'): 0.45454545454545453,\n",
              " ('3503341808', '628067938'): 0.45454545454545453,\n",
              " ('350371951', '1301130341'): 0.75,\n",
              " ('3504495874', '2920099749'): 0.29411764705882354,\n",
              " ('3504495874', '4105496665'): 0.35294117647058826,\n",
              " ('3513528495', '2409754340'): 0.4,\n",
              " ('3518637264', '3214201835'): 0.38461538461538464,\n",
              " ('3520507611', '1765954746'): 0.38461538461538464,\n",
              " ('3524859265', '2209025073'): 0.5555555555555556,\n",
              " ('3524859265', '3186714689'): 0.5555555555555556,\n",
              " ('3524859265', '3348014232'): 0.8888888888888888,\n",
              " ('3524859265', '4014848395'): 0.5555555555555556,\n",
              " ('3524859265', '752036747'): 0.5555555555555556,\n",
              " ('3525728115', '1356029419'): 0.4230769230769231,\n",
              " ('3525728115', '2144575575'): 0.2692307692307692,\n",
              " ('3525728115', '2938586062'): 0.2692307692307692,\n",
              " ('3527919983', '3969710286'): 0.1111111111111111,\n",
              " ('3532824385', '1434510306'): 0.8333333333333334,\n",
              " ('3532824385', '3536446306'): 0.8333333333333334,\n",
              " ('3532968979', '4147728743'): 0.625,\n",
              " ('3536446306', '1434510306'): 0.23809523809523808,\n",
              " ('3536446306', '3532824385'): 0.23809523809523808,\n",
              " ('3548737114', '139882176'): 1.0,\n",
              " ('357497635', '4084437551'): 0.7142857142857143,\n",
              " ('3578772690', '2417453396'): 0.5,\n",
              " ('3588221934', '2422423164'): 0.25,\n",
              " ('3588221934', '556693442'): 0.25,\n",
              " ('3611536849', '819479719'): 0.45454545454545453,\n",
              " ('3627018934', '696248520'): 0.5555555555555556,\n",
              " ('3635476228', '264396596'): 1.0,\n",
              " ('3637995760', '73762773'): 1.0,\n",
              " ('3649059762', '3503341808'): 0.7142857142857143,\n",
              " ('3654121371', '300276821'): 0.625,\n",
              " ('3668074915', '3988619959'): 0.3,\n",
              " ('3681725342', '584759982'): 1.0,\n",
              " ('3685069970', '2037654457'): 0.21739130434782608,\n",
              " ('3685069970', '2555193367'): 0.21739130434782608,\n",
              " ('3685069970', '3455627795'): 0.2608695652173913,\n",
              " ('3685069970', '4247870098'): 0.30434782608695654,\n",
              " ('3686824712', '1453106299'): 0.875,\n",
              " ('3692015285', '59111799'): 0.8571428571428571,\n",
              " ('3694254632', '278301913'): 0.5,\n",
              " ('369741937', '3064964030'): 0.8333333333333334,\n",
              " ('369741937', '4097041451'): 1.0,\n",
              " ('3698777560', '897182880'): 0.4166666666666667,\n",
              " ('3701030057', '1197233505'): 0.14285714285714285,\n",
              " ('3701030057', '1298253901'): 0.16071428571428573,\n",
              " ('3701030057', '2052357883'): 0.08928571428571429,\n",
              " ('3701030057', '2653997740'): 0.26785714285714285,\n",
              " ('3701030057', '332587789'): 0.14285714285714285,\n",
              " ('3727675481', '4147728743'): 0.2857142857142857,\n",
              " ('3753654154', '992097354'): 0.5555555555555556,\n",
              " ('3754036067', '1124147890'): 0.625,\n",
              " ('3754036067', '2074836467'): 0.625,\n",
              " ('3754036067', '2542911636'): 0.75,\n",
              " ('3772333781', '1624151051'): 0.3333333333333333,\n",
              " ('3785285448', '3250827323'): 0.2857142857142857,\n",
              " ('3785285448', '696150941'): 0.42857142857142855,\n",
              " ('3786443633', '2189852989'): 0.4166666666666667,\n",
              " ('3804260007', '2977262011'): 0.8571428571428571,\n",
              " ('3811033060', '1484653162'): 1.0,\n",
              " ('3811033060', '3337000328'): 1.0,\n",
              " ('3825026050', '2801340362'): 1.0,\n",
              " ('3828331305', '2162970570'): 1.0,\n",
              " ('3841123463', '120931195'): 1.0,\n",
              " ('3842023916', '2953404574'): 0.6470588235294118,\n",
              " ('3842023916', '819479719'): 0.6470588235294118,\n",
              " ('3845519378', '3476740986'): 1.0,\n",
              " ('3849532435', '2499359404'): 0.38461538461538464,\n",
              " ('3849532435', '2507645664'): 0.46153846153846156,\n",
              " ('3851951791', '60608325'): 0.6666666666666666,\n",
              " ('3879150379', '2439282353'): 0.29411764705882354,\n",
              " ('3879150379', '3201311000'): 0.29411764705882354,\n",
              " ('3884244346', '1278880239'): 1.0,\n",
              " ('3884244346', '296623680'): 1.0,\n",
              " ('3892126620', '3014861976'): 0.6666666666666666,\n",
              " ('3900436160', '2542783'): 0.2222222222222222,\n",
              " ('3913668047', '3958298651'): 0.45454545454545453,\n",
              " ('3922099509', '3348014232'): 1.0,\n",
              " ('3931865863', '2512988594'): 0.8333333333333334,\n",
              " ('3931865863', '470696179'): 1.0,\n",
              " ('3933211412', '4290608040'): 0.5555555555555556,\n",
              " ('3934986721', '2449357786'): 0.7777777777777778,\n",
              " ('39452777', '2360451987'): 0.7058823529411765,\n",
              " ('39452777', '3971736619'): 0.29411764705882354,\n",
              " ('3958298651', '3913668047'): 1.0,\n",
              " ('3969710286', '3527919983'): 1.0,\n",
              " ('3971736619', '1483274840'): 0.38095238095238093,\n",
              " ('3971736619', '39452777'): 0.23809523809523808,\n",
              " ('397746936', '2196659065'): 0.4166666666666667,\n",
              " ('397746936', '804407327'): 0.6666666666666666,\n",
              " ('3988619959', '3668074915'): 0.6666666666666666,\n",
              " ('3993255746', '1453106299'): 1.0,\n",
              " ('4003009412', '2108554754'): 0.38461538461538464,\n",
              " ('4014848395', '2209025073'): 0.5,\n",
              " ('4014848395', '3186714689'): 0.7142857142857143,\n",
              " ('4014848395', '3348014232'): 0.42857142857142855,\n",
              " ('4014848395', '3524859265'): 0.35714285714285715,\n",
              " ('4014848395', '752036747'): 0.5714285714285714,\n",
              " ('4017234740', '1029829025'): 0.28,\n",
              " ('4017234740', '4118445004'): 0.2,\n",
              " ('401810495', '3198137693'): 0.3333333333333333,\n",
              " ('40191102', '406844425'): 0.15625,\n",
              " ('4023531158', '86810146'): 1.0,\n",
              " ('4028600581', '1118746000'): 1.0,\n",
              " ('4028600581', '1514060377'): 1.0,\n",
              " ('4028600581', '1802347277'): 1.0,\n",
              " ('4028600581', '2433797681'): 1.0,\n",
              " ('4028600581', '645710987'): 1.0,\n",
              " ('4032439473', '1407649050'): 1.0,\n",
              " ('4046848336', '2073669856'): 0.29411764705882354,\n",
              " ('4066690169', '1950083015'): 0.25,\n",
              " ('4066690169', '2048560962'): 0.3,\n",
              " ('4066690169', '2542659056'): 0.25,\n",
              " ('406844425', '1050619812'): 0.2631578947368421,\n",
              " ('406844425', '40191102'): 0.2631578947368421,\n",
              " ('4071730666', '3463828400'): 0.625,\n",
              " ('4071730666', '4097041451'): 1.0,\n",
              " ('4084437551', '357497635'): 0.38461538461538464,\n",
              " ('4085136918', '3186714689'): 0.45454545454545453,\n",
              " ('4096709471', '2590033134'): 0.3125,\n",
              " ('4096709471', '3457012981'): 0.375,\n",
              " ('4097041451', '1007220190'): 0.14285714285714285,\n",
              " ('4097041451', '3064964030'): 0.14285714285714285,\n",
              " ('4097041451', '3386749996'): 0.11904761904761904,\n",
              " ('4097041451', '3463828400'): 0.2619047619047619,\n",
              " ('4097041451', '369741937'): 0.14285714285714285,\n",
              " ('4097041451', '4071730666'): 0.19047619047619047,\n",
              " ('4105496665', '3504495874'): 1.0,\n",
              " ('4118445004', '1457781808'): 0.2608695652173913,\n",
              " ('4118445004', '4017234740'): 0.21739130434782608,\n",
              " ('4118445004', '4261081585'): 0.21739130434782608,\n",
              " ('4124092616', '2016878527'): 0.35714285714285715,\n",
              " ('4124092616', '2253152241'): 0.5,\n",
              " ('4124092616', '3375657602'): 0.6428571428571429,\n",
              " ('4144433279', '1001356832'): 1.0,\n",
              " ('4147728743', '2580014233'): 0.2916666666666667,\n",
              " ('4147728743', '3532968979'): 0.20833333333333334,\n",
              " ('4147728743', '3727675481'): 0.25,\n",
              " ('4147961697', '1694623627'): 1.0,\n",
              " ('4147961697', '2684856415'): 1.0,\n",
              " ('4160523084', '1245326756'): 0.35,\n",
              " ('4192645038', '2319707579'): 1.0,\n",
              " ('4206321234', '4291011376'): 0.8333333333333334,\n",
              " ('4207443520', '1407649050'): 0.6,\n",
              " ('4217676389', '997201626'): 0.4166666666666667,\n",
              " ('4220744926', '2512988594'): 1.0,\n",
              " ('4220744926', '470696179'): 1.0,\n",
              " ('4229676404', '1463160344'): 0.9285714285714286,\n",
              " ('4229676404', '791375045'): 0.17857142857142858,\n",
              " ('4241672560', '3408529014'): 0.38461538461538464,\n",
              " ('4244144558', '1446694012'): 0.75,\n",
              " ('4244543344', '2885783340'): 0.3125,\n",
              " ('4247870098', '3685069970'): 0.875,\n",
              " ('4260611607', '3326952743'): 0.625,\n",
              " ('4261081585', '1457781808'): 0.23809523809523808,\n",
              " ('4261081585', '4118445004'): 0.23809523809523808,\n",
              " ('4261650261', '2355635187'): 0.8571428571428571,\n",
              " ('4261650261', '819479719'): 1.0,\n",
              " ('4267504215', '1205208901'): 0.16216216216216217,\n",
              " ('4267504215', '3214201835'): 0.16216216216216217,\n",
              " ('427015018', '3413046455'): 0.6666666666666666,\n",
              " ('4272876618', '2277587473'): 0.22727272727272727,\n",
              " ('4272876618', '53147213'): 0.45454545454545453,\n",
              " ('4282252781', '1345978760'): 0.8333333333333334,\n",
              " ('428475226', '1029041475'): 0.6666666666666666,\n",
              " ('4285944361', '214150511'): 0.45454545454545453,\n",
              " ('4290608040', '3933211412'): 0.8333333333333334,\n",
              " ('4291011376', '4206321234'): 1.0,\n",
              " ('434709649', '3408529014'): 1.0,\n",
              " ('447265668', '2389259247'): 0.25925925925925924,\n",
              " ('468320348', '3285887257'): 0.21428571428571427,\n",
              " ('470696179', '1232791679'): 0.2,\n",
              " ('470696179', '125624950'): 0.22857142857142856,\n",
              " ('470696179', '2512988594'): 0.7142857142857143,\n",
              " ('470696179', '2834131571'): 0.17142857142857143,\n",
              " ('470696179', '3931865863'): 0.17142857142857143,\n",
              " ('470696179', '4220744926'): 0.2,\n",
              " ('471388580', '135626747'): 0.3125,\n",
              " ('497251668', '1277831649'): 0.7,\n",
              " ('497251668', '1290887240'): 0.6,\n",
              " ('507167216', '300276821'): 0.3181818181818182,\n",
              " ('51129094', '1531433927'): 0.8,\n",
              " ('512356224', '2575668150'): 0.5833333333333334,\n",
              " ('53147213', '2277587473'): 0.2608695652173913,\n",
              " ('53147213', '4272876618'): 0.43478260869565216,\n",
              " ('536067059', '2590033134'): 1.0,\n",
              " ('537641887', '617064953'): 0.5555555555555556,\n",
              " ('542800332', '172470197'): 0.5555555555555556,\n",
              " ('556240111', '1307276742'): 0.6111111111111112,\n",
              " ('556693442', '3588221934'): 1.0,\n",
              " ('563124937', '69789647'): 0.625,\n",
              " ('572884180', '1695285895'): 0.8333333333333334,\n",
              " ('576264751', '1369219426'): 0.08860759493670886,\n",
              " ('576264751', '1786313808'): 0.06329113924050633,\n",
              " ('576264751', '2241342514'): 0.12658227848101267,\n",
              " ('576264751', '2678532305'): 0.06329113924050633,\n",
              " ('576264751', '3253308491'): 0.10126582278481013,\n",
              " ('576264751', '881126740'): 0.08860759493670886,\n",
              " ('576264751', '992097354'): 0.06329113924050633,\n",
              " ('579147290', '2009191947'): 1.0,\n",
              " ('584759982', '111482447'): 0.22727272727272727,\n",
              " ('584759982', '2159519621'): 0.36363636363636365,\n",
              " ('584759982', '3681725342'): 0.2727272727272727,\n",
              " ('59111799', '3692015285'): 0.3,\n",
              " ('60608325', '188875566'): 0.3125,\n",
              " ('60608325', '3851951791'): 0.375,\n",
              " ('608152706', '947363407'): 1.0,\n",
              " ('61367588', '3151851971'): 1.0,\n",
              " ('614867846', '1699152513'): 0.45454545454545453,\n",
              " ('615028091', '3279006093'): 0.20833333333333334,\n",
              " ('616314303', '2654352847'): 0.5,\n",
              " ('616314303', '269711433'): 0.5,\n",
              " ('617064953', '537641887'): 1.0,\n",
              " ('626984693', '236129479'): 0.16666666666666666,\n",
              " ('626984693', '3012790832'): 0.16666666666666666,\n",
              " ('626984693', '719769265'): 0.23333333333333334,\n",
              " ('628067938', '3503341808'): 0.5555555555555556,\n",
              " ('633084345', '1348681189'): 0.75,\n",
              " ('63454557', '3027306743'): 1.0,\n",
              " ('645710987', '1118746000'): 1.0,\n",
              " ('645710987', '1514060377'): 1.0,\n",
              " ('645710987', '1802347277'): 1.0,\n",
              " ('645710987', '2433797681'): 1.0,\n",
              " ('645710987', '4028600581'): 1.0,\n",
              " ('652971096', '300276821'): 0.875,\n",
              " ('660199781', '2971867906'): 0.5,\n",
              " ('665645192', '141266136'): 0.21428571428571427,\n",
              " ('682380085', '1271151121'): 0.1875,\n",
              " ('682380085', '1414649122'): 0.25,\n",
              " ('682380085', '2968640146'): 0.15625,\n",
              " ('696150941', '3785285448'): 0.9,\n",
              " ('696248520', '3627018934'): 0.3125,\n",
              " ('69789647', '563124937'): 0.625,\n",
              " ('70519573', '3257075704'): 0.3888888888888889,\n",
              " ('712864023', '2653997740'): 1.0,\n",
              " ('719769265', '626984693'): 0.7777777777777778,\n",
              " ('73762773', '3637995760'): 0.3125,\n",
              " ('748457644', '1001356832'): 1.0,\n",
              " ('752036747', '2209025073'): 0.625,\n",
              " ('752036747', '3186714689'): 0.875,\n",
              " ('752036747', '3348014232'): 0.625,\n",
              " ('752036747', '3524859265'): 0.625,\n",
              " ('752036747', '4014848395'): 1.0,\n",
              " ('789170565', '2270472327'): 1.0,\n",
              " ('791375045', '1463160344'): 0.42857142857142855,\n",
              " ('791375045', '4229676404'): 0.35714285714285715,\n",
              " ('800578314', '2536764768'): 1.0,\n",
              " ('804407327', '1245517116'): 0.2631578947368421,\n",
              " ('804407327', '1608947994'): 0.2631578947368421,\n",
              " ('804407327', '2196659065'): 0.47368421052631576,\n",
              " ('804407327', '247595010'): 0.6842105263157895,\n",
              " ('804407327', '397746936'): 0.42105263157894735,\n",
              " ('819217306', '2507645664'): 0.7142857142857143,\n",
              " ('819479719', '1326939511'): 0.10869565217391304,\n",
              " ('819479719', '2355635187'): 0.15217391304347827,\n",
              " ('819479719', '2953404574'): 0.34782608695652173,\n",
              " ('819479719', '3611536849'): 0.10869565217391304,\n",
              " ('819479719', '3842023916'): 0.2391304347826087,\n",
              " ('819479719', '4261650261'): 0.15217391304347827,\n",
              " ('852235790', '1705842678'): 0.28,\n",
              " ('862747054', '2806264397'): 1.0,\n",
              " ('86810146', '139882176'): 0.3,\n",
              " ('86810146', '4023531158'): 0.3,\n",
              " ('872811929', '1054694307'): 0.5833333333333334,\n",
              " ('872811929', '1345978760'): 0.4166666666666667,\n",
              " ('872811929', '2944703640'): 0.6666666666666666,\n",
              " ('880638866', '1453106299'): 1.0,\n",
              " ('881126740', '576264751'): 0.3684210526315789,\n",
              " ('881126740', '992097354'): 0.2631578947368421,\n",
              " ('894788450', '2029349294'): 0.6470588235294118,\n",
              " ('897182880', '3497747092'): 0.12195121951219512,\n",
              " ('897182880', '3698777560'): 0.12195121951219512,\n",
              " ('920692749', '3148062437'): 1.0,\n",
              " ('939467845', '2548984784'): 0.4166666666666667,\n",
              " ('944216118', '188875566'): 0.3,\n",
              " ('944216118', '2858857601'): 0.25,\n",
              " ('946584363', '3417893845'): 0.7058823529411765,\n",
              " ('947363407', '608152706'): 0.38461538461538464,\n",
              " ('964183707', '1626978279'): 0.1388888888888889,\n",
              " ('964183707', '2580509263'): 0.19444444444444445,\n",
              " ('964183707', '304107480'): 0.1388888888888889,\n",
              " ('971549563', '2299019096'): 0.4166666666666667,\n",
              " ('971549563', '3246355936'): 0.20833333333333334,\n",
              " ('992097354', '3753654154'): 0.2777777777777778,\n",
              " ('992097354', '576264751'): 0.2777777777777778,\n",
              " ('992097354', '881126740'): 0.2777777777777778,\n",
              " ('997201626', '4217676389'): 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perfect implications\n",
        "\n",
        "Some associations have a confidence of 1. which means occurance of $\\{i_1\\}$ is completely determined by occurance of $\\{i_2,\\dots,i_n\\}$.\n",
        "\n",
        "These associations rules can be thought of as implications. For example, if $X \\to Y$ has a confidence of 1, then, if we see $X$ in an item basket, we will be sure that $Y$ also exists in that item basket (given our limited knowledge of the universe based on the dataset of course!)."
      ],
      "metadata": {
        "id": "MH0WWwUFiiXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answering question 3\n",
        "\n",
        "which frequent authors, have always colaborated with a specific co-author.\n",
        "\n",
        "We will consider a support threshold of 5 papers (pairs must have at least 5 papers together to be considered frequent) and require the confidence of association to be 1 (perfect implication)."
      ],
      "metadata": {
        "id": "P3WnA4hEr-0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perfect implications for support value 5\n",
        "# having written at least 5 NIPS papers together\n",
        "for k in associations:\n",
        "  if associations[k] == 1.0:\n",
        "    X = id_2_author[int(k[0])]\n",
        "    Y = id_2_author[int(k[1])]\n",
        "    print(f'{X} -> {Y}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIYS_pVBduyC",
        "outputId": "c1b9c49c-38a1-4ddd-8f47-278bcdd631c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebastian Mika -> Gunnar Rätsch\n",
            "Andreas Ziehe -> Klaus-Robert Müller\n",
            "Benjamin Blankertz -> Klaus-Robert Müller\n",
            "Bernd Porr -> Florentin Wörgötter\n",
            "Corinna Cortes -> Mehryar Mohri\n",
            "Hongjing Lu -> Alan L. Yuille\n",
            "Dongryeol Lee -> Alexander Gray\n",
            "Xuejun Liao -> Lawrence Carin\n",
            "Phil Long -> Rocco Servedio\n",
            "Michael Lyu -> Irwin King\n",
            "Alyson K. Fletcher -> Sundeep Rangan\n",
            "Sundeep Rangan -> Alyson K. Fletcher\n",
            "Jun Liu -> Jieping Ye\n",
            "Yao-liang Yu -> Dale Schuurmans\n",
            "Arthur Choi -> Adnan Darwiche\n",
            "Richard L. Lewis -> Satinder Singh\n",
            "Arthur Guez -> David Silver\n",
            "Fang Han -> Han Liu\n",
            "Sanghack Lee -> Elias Bareinboim\n",
            "Rishabh K. Iyer -> Jeff A. Bilmes\n",
            "Itay Hubara -> Daniel Soudry\n",
            "Greg Ver Steeg -> Aram Galstyan\n",
            "Vitaly Kuznetsov -> Mehryar Mohri\n",
            "Scott Yang -> Mehryar Mohri\n",
            "Xiangru Lian -> Ji Liu\n",
            "Jean-Bastien Grill -> Michal Valko\n",
            "Kevin Ellis -> Josh Tenenbaum\n",
            "Kiran K. Thekumparampil -> Sewoong Oh\n",
            "Felix Xinnan X. Yu -> Sanjiv Kumar\n",
            "Ashish Khetan -> Sewoong Oh\n",
            "Hakan Bilen -> Andrea Vedaldi\n",
            "Shengjia Zhao -> Stefano Ermon\n",
            "Matteo Hessel -> Hado P. van Hasselt\n",
            "Yingce Xia -> Tie-Yan Liu\n",
            "jean barbier -> Nicolas Macris\n",
            "Yan Duan -> Pieter Abbeel\n",
            "Rein Houthooft -> Pieter Abbeel\n",
            "Matteo Turchetta -> Andreas Krause\n",
            "Mingsheng Long -> Jianmin Wang\n",
            "Jianmin Wang -> Mingsheng Long\n",
            "Dilin Wang -> Qiang Liu\n",
            "Pan Xu -> Quanquan Gu\n",
            "Ahmed M. Alaa -> Mihaela van der Schaar\n",
            "Luigi Carratino -> Lorenzo Rosasco\n",
            "Luiz Chamon -> Alejandro Ribeiro\n",
            "Sunil Gupta -> Santu Rana\n",
            "Santu Rana -> Sunil Gupta\n",
            "Santu Rana -> Svetha Venkatesh\n",
            "Sunil Gupta -> Svetha Venkatesh\n",
            "Soumyabrata Pal -> Arya Mazumdar\n",
            "Chongxuan LI -> Jun Zhu\n",
            "Liqun Chen -> Lawrence Carin\n",
            "Zhitao Ying -> Jure Leskovec\n",
            "Daisuke Hatano -> Shinji Ito\n",
            "Hanna Sumita -> Shinji Ito\n",
            "Takuro Fukunaga -> Shinji Ito\n",
            "Naonori Kakimura -> Shinji Ito\n",
            "Ken-Ichi Kawarabayashi -> Shinji Ito\n",
            "Daisuke Hatano -> Hanna Sumita\n",
            "Hanna Sumita -> Daisuke Hatano\n",
            "Takuro Fukunaga -> Daisuke Hatano\n",
            "Daisuke Hatano -> Takuro Fukunaga\n",
            "Naonori Kakimura -> Daisuke Hatano\n",
            "Daisuke Hatano -> Naonori Kakimura\n",
            "Daisuke Hatano -> Ken-Ichi Kawarabayashi\n",
            "Ken-Ichi Kawarabayashi -> Daisuke Hatano\n",
            "Takuro Fukunaga -> Hanna Sumita\n",
            "Hanna Sumita -> Takuro Fukunaga\n",
            "Naonori Kakimura -> Hanna Sumita\n",
            "Hanna Sumita -> Naonori Kakimura\n",
            "Ken-Ichi Kawarabayashi -> Hanna Sumita\n",
            "Hanna Sumita -> Ken-Ichi Kawarabayashi\n",
            "Takuro Fukunaga -> Naonori Kakimura\n",
            "Naonori Kakimura -> Takuro Fukunaga\n",
            "Takuro Fukunaga -> Ken-Ichi Kawarabayashi\n",
            "Ken-Ichi Kawarabayashi -> Takuro Fukunaga\n",
            "Naonori Kakimura -> Ken-Ichi Kawarabayashi\n",
            "Ken-Ichi Kawarabayashi -> Naonori Kakimura\n",
            "Moran Feldman -> Amin Karbasi\n",
            "Sreeram Kannan -> Pramod Viswanath\n",
            "Wenbing Huang -> Junzhou Huang\n",
            "Alberto Maria Metelli -> Marcello Restelli\n",
            "Zhongwen Xu -> Hado P. van Hasselt\n",
            "Zhongwen Xu -> David Silver\n",
            "Yu Rong -> Junzhou Huang\n",
            "Chenyang Tao -> Lawrence Carin\n",
            "Amir Gholami -> Michael W. Mahoney\n",
            "Dongruo Zhou -> Quanquan Gu\n",
            "Ricky T. Q. Chen -> David K. Duvenaud\n",
            "Alistair Stewart -> Ilias Diakonikolas\n",
            "Xu Tan -> Tao Qin\n",
            "Xu Tan -> Tie-Yan Liu\n",
            "Rosanne Liu -> Jason Yosinski\n",
            "Ali Kavis -> Volkan Cevher\n",
            "Zeming Li -> Jian Sun\n",
            "Stanley Osher -> Bao Wang\n",
            "Bao Wang -> Stanley Osher\n",
            "Guangxiang Zhu -> Chongjie Zhang\n",
            "Manish Purohit -> Ravi Kumar\n",
            "Ying Nian Wu -> Song-Chun Zhu\n",
            "Albert Gu -> Christopher Ré\n",
            "Dimitris Tsipras -> Shibani Santurkar\n",
            "Shibani Santurkar -> Dimitris Tsipras\n",
            "Shibani Santurkar -> Aleksander Madry\n",
            "Dimitris Tsipras -> Aleksander Madry\n",
            "Andrew Ilyas -> Aleksander Madry\n",
            "Difan Zou -> Quanquan Gu\n",
            "Kevin Bello -> Jean Honorio\n",
            "Xiaohan Chen -> Zhangyang Wang\n",
            "Minshuo Chen -> Tuo Zhao\n",
            "Jiaxuan You -> Jure Leskovec\n",
            "Tianyu Pang -> Jun Zhu\n",
            "Yinpeng Dong -> Jun Zhu\n",
            "Dmitry Kovalev -> Peter Richtarik\n",
            "Anirvan Sengupta -> Dmitri Chklovskii\n",
            "Mingli Song -> Xinchao Wang\n",
            "Xinchao Wang -> Mingli Song\n",
            "Greg Lewis -> Vasilis Syrgkanis\n",
            "Colin Wei -> Tengyu Ma\n",
            "Zhongxiang Dai -> Bryan Kian Hsiang Low\n",
            "Bruno Loureiro -> Florent Krzakala\n",
            "Bruno Loureiro -> Lenka Zdeborová\n",
            "Tianhe Yu -> Chelsea Finn\n",
            "Hang Su -> Jun Zhu\n",
            "Tamer Basar -> Kaiqing Zhang\n",
            "Kaiqing Zhang -> Tamer Basar\n",
            "Chenlin Meng -> Stefano Ermon\n",
            "Andrea Zanette -> Emma Brunskill\n",
            "Li Zhao -> Tie-Yan Liu\n",
            "Emiel Hoogeboom -> Max Welling\n",
            "Yiheng Lin -> Adam Wierman\n",
            "Gen Li -> Yuxin Chen\n",
            "Daniel Jarrett -> Mihaela van der Schaar\n",
            "Tianlong Chen -> Zhangyang Wang\n",
            "Ioana Bica -> Mihaela van der Schaar\n",
            "Zhaozhi Qian -> Mihaela van der Schaar\n",
            "Xingchao Liu -> Qiang Liu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "\n",
        "## Confidence vs. Interestingness\n",
        "\n",
        "One criticism of confidence measure is that it might not return truly interesting results. For example, consider a market basket example. Suppose the basket $\\{milk, bread\\}$ is frequent and $[milk \\to bread]$ has high confidence. This means that many customers bought milk and bread together, and if a basket contains milk then with high probability it contains bread.\n",
        "\n",
        "This seems an interesting association rule, but consider if bread is bought so commonly that most baskets contain bread irrespective of whether it also contained milk or not. In this situation $[milk \\to bread]$ is not interesting because we can replace milk with any other frequent item and still get a high confidence association rule.\n",
        "\n",
        "To remedy this issue, we can use \"interestingness\" which measures the gap between confidence of $[x\\to y]$ and probability of $y$ being in a given basket,\n",
        "$$\n",
        "\\text{interest}(x \\to y) = |\\text{conf}(x \\to y) - P[y]|.\n",
        "$$\n",
        "\n",
        "In our specific work however we don't need to worry about this problem because (as mentioned before) the most published author has 79 NurIPS papers, in comparison to 12461 total papers. Therefore, no author has a high probability of working on a given paper ($P[y] \\approx 0$) which implies that in our study,\n",
        "$$\n",
        "\\text{interest}(x \\to y) \\approx \\text{conf}(x \\to y).\n",
        "$$\n",
        "\n",
        "## Future work\n",
        "\n",
        "There are a lot of areas for investigation when it comes to analyzing publications and relationship between them. Here we mention two such avenues for future research.\n",
        "\n",
        "### References association mining\n",
        "\n",
        "We can perform a market basket analysis (similar to what we performed here) on references of each paper. This might reveal interesting co-citation relationships between papers and frequent co-citations can lead to recognition of bundles of few papers at the core of each research area. This can ease the process of reading and understanding the literature.\n",
        "\n",
        "### Tracking impact of a paper with PageRank\n",
        "\n",
        "Consider a graph where each node is a paper and edges are references between papers. In this model, a topic specific PageRank with a teleport set of $\\{x\\}$ can illuminate the reach of $x$ as it's effect flows through the network of papers.\n",
        "\n",
        "\n",
        "## Final note\n",
        "\n",
        "The final objective of the study at hand and these potential avenues for expansion is to better navigate the large volume of research articles being published every year. To help students and researchers by deligating the task of finding good papers and focusing on understanding relationships and connections."
      ],
      "metadata": {
        "id": "c1y19gHodzz1"
      }
    }
  ]
}